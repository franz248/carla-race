2023-12-30 01:08:40.746453: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-12-30 01:08:40.931824: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2023-12-30 01:08:40.931956: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2023-12-30 01:08:40.955246: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2023-12-30 01:08:41.007787: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-12-30 01:08:41.629131: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-12-30 01:08:42.270188: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-12-30 01:08:42.443683: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-12-30 01:08:42.444406: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-12-30 01:08:42.460257: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-12-30 01:08:42.460961: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-12-30 01:08:42.461211: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-12-30 01:08:43.453204: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-12-30 01:08:43.453336: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-12-30 01:08:43.453433: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-12-30 01:08:43.453590: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4395 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 SUPER, pci bus id: 0000:02:00.0, compute capability: 7.5
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d_input (InputLayer)   [(None, 128, 128, 3)]     0         
                                                                 
 conv2d (Conv2D)             (None, 128, 128, 64)      1792      
                                                                 
 max_pooling2d (MaxPooling2  (None, 64, 64, 64)        0         
 D)                                                              
                                                                 
 batch_normalization (Batch  (None, 64, 64, 64)        256       
 Normalization)                                                  
                                                                 
 activation (Activation)     (None, 64, 64, 64)        0         
                                                                 
 conv2d_1 (Conv2D)           (None, 64, 64, 64)        36928     
                                                                 
 max_pooling2d_1 (MaxPoolin  (None, 32, 32, 64)        0         
 g2D)                                                            
                                                                 
 batch_normalization_1 (Bat  (None, 32, 32, 64)        256       
 chNormalization)                                                
                                                                 
 activation_1 (Activation)   (None, 32, 32, 64)        0         
                                                                 
 conv2d_2 (Conv2D)           (None, 32, 32, 64)        36928     
                                                                 
 max_pooling2d_2 (MaxPoolin  (None, 16, 16, 64)        0         
 g2D)                                                            
                                                                 
 batch_normalization_2 (Bat  (None, 16, 16, 64)        256       
 chNormalization)                                                
                                                                 
 activation_2 (Activation)   (None, 16, 16, 64)        0         
                                                                 
 conv2d_3 (Conv2D)           (None, 16, 16, 64)        36928     
                                                                 
 max_pooling2d_3 (MaxPoolin  (None, 8, 8, 64)          0         
 g2D)                                                            
                                                                 
 batch_normalization_3 (Bat  (None, 8, 8, 64)          256       
 chNormalization)                                                
                                                                 
 activation_3 (Activation)   (None, 8, 8, 64)          0         
                                                                 
 flatten (Flatten)           (None, 4096)              0         
                                                                 
 dense (Dense)               (None, 2541)              10410477  
                                                                 
=================================================================
Total params: 10524077 (40.15 MB)
Trainable params: 10523565 (40.14 MB)
Non-trainable params: 512 (2.00 KB)
_________________________________________________________________
None
Model: "model_1"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d_4_input (InputLayer  [(None, 128, 128, 3)]     0         
 )                                                               
                                                                 
 conv2d_4 (Conv2D)           (None, 128, 128, 64)      1792      
                                                                 
 max_pooling2d_4 (MaxPoolin  (None, 64, 64, 64)        0         
 g2D)                                                            
                                                                 
 batch_normalization_4 (Bat  (None, 64, 64, 64)        256       
 chNormalization)                                                
                                                                 
 activation_4 (Activation)   (None, 64, 64, 64)        0         
                                                                 
 conv2d_5 (Conv2D)           (None, 64, 64, 64)        36928     
                                                                 
 max_pooling2d_5 (MaxPoolin  (None, 32, 32, 64)        0         
 g2D)                                                            
                                                                 
 batch_normalization_5 (Bat  (None, 32, 32, 64)        256       
 chNormalization)                                                
                                                                 
 activation_5 (Activation)   (None, 32, 32, 64)        0         
                                                                 
 conv2d_6 (Conv2D)           (None, 32, 32, 64)        36928     
                                                                 
 max_pooling2d_6 (MaxPoolin  (None, 16, 16, 64)        0         
 g2D)                                                            
                                                                 
 batch_normalization_6 (Bat  (None, 16, 16, 64)        256       
 chNormalization)                                                
                                                                 
 activation_6 (Activation)   (None, 16, 16, 64)        0         
                                                                 
 conv2d_7 (Conv2D)           (None, 16, 16, 64)        36928     
                                                                 
 max_pooling2d_7 (MaxPoolin  (None, 8, 8, 64)          0         
 g2D)                                                            
                                                                 
 batch_normalization_7 (Bat  (None, 8, 8, 64)          256       
 chNormalization)                                                
                                                                 
 activation_7 (Activation)   (None, 8, 8, 64)          0         
                                                                 
 flatten_1 (Flatten)         (None, 4096)              0         
                                                                 
 dense_1 (Dense)             (None, 2541)              10410477  
                                                                 
=================================================================
Total params: 10524077 (40.15 MB)
Trainable params: 10523565 (40.14 MB)
Non-trainable params: 512 (2.00 KB)
_________________________________________________________________
None
Model: "model_2"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d_8_input (InputLayer  [(None, 128, 128, 3)]     0         
 )                                                               
                                                                 
 conv2d_8 (Conv2D)           (None, 128, 128, 64)      1792      
                                                                 
 max_pooling2d_8 (MaxPoolin  (None, 64, 64, 64)        0         
 g2D)                                                            
                                                                 
 batch_normalization_8 (Bat  (None, 64, 64, 64)        256       
 chNormalization)                                                
                                                                 
 activation_8 (Activation)   (None, 64, 64, 64)        0         
                                                                 
 conv2d_9 (Conv2D)           (None, 64, 64, 64)        36928     
                                                                 
 max_pooling2d_9 (MaxPoolin  (None, 32, 32, 64)        0         
 g2D)                                                            
                                                                 
 batch_normalization_9 (Bat  (None, 32, 32, 64)        256       
 chNormalization)                                                
                                                                 
 activation_9 (Activation)   (None, 32, 32, 64)        0         
                                                                 
 conv2d_10 (Conv2D)          (None, 32, 32, 64)        36928     
                                                                 
 max_pooling2d_10 (MaxPooli  (None, 16, 16, 64)        0         
 ng2D)                                                           
                                                                 
 batch_normalization_10 (Ba  (None, 16, 16, 64)        256       
 tchNormalization)                                               
                                                                 
 activation_10 (Activation)  (None, 16, 16, 64)        0         
                                                                 
 conv2d_11 (Conv2D)          (None, 16, 16, 64)        36928     
                                                                 
 max_pooling2d_11 (MaxPooli  (None, 8, 8, 64)          0         
 ng2D)                                                           
                                                                 
 batch_normalization_11 (Ba  (None, 8, 8, 64)          256       
 tchNormalization)                                               
                                                                 
 activation_11 (Activation)  (None, 8, 8, 64)          0         
                                                                 
 flatten_2 (Flatten)         (None, 4096)              0         
                                                                 
 dense_2 (Dense)             (None, 2541)              10410477  
                                                                 
=================================================================
Total params: 10524077 (40.15 MB)
Trainable params: 10523565 (40.14 MB)
Non-trainable params: 512 (2.00 KB)
_________________________________________________________________
None
WARNING: Version mismatch detected: You are trying to connect to a simulator that might be incompatible with this API 
WARNING: Client API version     = 0.9.15 
WARNING: Simulator API version  = 0.9.14 
2023-12-30 01:09:02.285379: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904
2023-12-30 01:09:03.832721: I external/local_xla/xla/service/service.cc:168] XLA service 0x7fcd835aa690 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-12-30 01:09:03.832735: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 SUPER, Compute Capability 7.5
2023-12-30 01:09:03.839974: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1703916543.922047    2429 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
  0%|          | 0/1000 [00:00<?, ?episode/s]
Started episode 1 of 1000
Finished training first epoch.
  0%|          | 0/1000 [02:32<?, ?episode/s]
Error message: 'Failed to add concrete function \'b\'__inference_predict_function_567252\'\' to object-based SavedModel as it captures tensor <tf.Tensor: shape=(), dtype=resource, value=<ResourceHandle(name="Variable/31", device="/job:localhost/replica:0/task:0/device:GPU:0", container="Anonymous", type="tensorflow::Var", dtype and shapes : "[ DType enum: 9, Shape: [] ]")>> which is unsupported or not reachable from root. One reason could be that a stateful object or a variable that the function depends on is not assigned to an attribute of the serialized trackable object (see SaveTest.test_captures_unreachable_variable).'
Error during episode 1
2023-12-30 01:12:10.136732: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-12-30 01:12:10.158649: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2023-12-30 01:12:10.158665: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2023-12-30 01:12:10.159447: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2023-12-30 01:12:10.162786: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-12-30 01:12:10.581169: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-12-30 01:12:10.882163: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-12-30 01:12:10.909659: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-12-30 01:12:10.909830: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-12-30 01:12:10.912459: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-12-30 01:12:10.912759: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-12-30 01:12:10.912971: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-12-30 01:12:11.649520: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-12-30 01:12:11.649671: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-12-30 01:12:11.649849: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-12-30 01:12:11.649930: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4395 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 SUPER, pci bus id: 0000:02:00.0, compute capability: 7.5
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d_input (InputLayer)   [(None, 128, 128, 3)]     0         
                                                                 
 conv2d (Conv2D)             (None, 128, 128, 64)      1792      
                                                                 
 max_pooling2d (MaxPooling2  (None, 64, 64, 64)        0         
 D)                                                              
                                                                 
 batch_normalization (Batch  (None, 64, 64, 64)        256       
 Normalization)                                                  
                                                                 
 activation (Activation)     (None, 64, 64, 64)        0         
                                                                 
 conv2d_1 (Conv2D)           (None, 64, 64, 64)        36928     
                                                                 
 max_pooling2d_1 (MaxPoolin  (None, 32, 32, 64)        0         
 g2D)                                                            
                                                                 
 batch_normalization_1 (Bat  (None, 32, 32, 64)        256       
 chNormalization)                                                
                                                                 
 activation_1 (Activation)   (None, 32, 32, 64)        0         
                                                                 
 conv2d_2 (Conv2D)           (None, 32, 32, 64)        36928     
                                                                 
 max_pooling2d_2 (MaxPoolin  (None, 16, 16, 64)        0         
 g2D)                                                            
                                                                 
 batch_normalization_2 (Bat  (None, 16, 16, 64)        256       
 chNormalization)                                                
                                                                 
 activation_2 (Activation)   (None, 16, 16, 64)        0         
                                                                 
 conv2d_3 (Conv2D)           (None, 16, 16, 64)        36928     
                                                                 
 max_pooling2d_3 (MaxPoolin  (None, 8, 8, 64)          0         
 g2D)                                                            
                                                                 
 batch_normalization_3 (Bat  (None, 8, 8, 64)          256       
 chNormalization)                                                
                                                                 
 activation_3 (Activation)   (None, 8, 8, 64)          0         
                                                                 
 flatten (Flatten)           (None, 4096)              0         
                                                                 
 dense (Dense)               (None, 2541)              10410477  
                                                                 
=================================================================
Total params: 10524077 (40.15 MB)
Trainable params: 10523565 (40.14 MB)
Non-trainable params: 512 (2.00 KB)
_________________________________________________________________
None
Model: "model_1"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d_4_input (InputLayer  [(None, 128, 128, 3)]     0         
 )                                                               
                                                                 
 conv2d_4 (Conv2D)           (None, 128, 128, 64)      1792      
                                                                 
 max_pooling2d_4 (MaxPoolin  (None, 64, 64, 64)        0         
 g2D)                                                            
                                                                 
 batch_normalization_4 (Bat  (None, 64, 64, 64)        256       
 chNormalization)                                                
                                                                 
 activation_4 (Activation)   (None, 64, 64, 64)        0         
                                                                 
 conv2d_5 (Conv2D)           (None, 64, 64, 64)        36928     
                                                                 
 max_pooling2d_5 (MaxPoolin  (None, 32, 32, 64)        0         
 g2D)                                                            
                                                                 
 batch_normalization_5 (Bat  (None, 32, 32, 64)        256       
 chNormalization)                                                
                                                                 
 activation_5 (Activation)   (None, 32, 32, 64)        0         
                                                                 
 conv2d_6 (Conv2D)           (None, 32, 32, 64)        36928     
                                                                 
 max_pooling2d_6 (MaxPoolin  (None, 16, 16, 64)        0         
 g2D)                                                            
                                                                 
 batch_normalization_6 (Bat  (None, 16, 16, 64)        256       
 chNormalization)                                                
                                                                 
 activation_6 (Activation)   (None, 16, 16, 64)        0         
                                                                 
 conv2d_7 (Conv2D)           (None, 16, 16, 64)        36928     
                                                                 
 max_pooling2d_7 (MaxPoolin  (None, 8, 8, 64)          0         
 g2D)                                                            
                                                                 
 batch_normalization_7 (Bat  (None, 8, 8, 64)          256       
 chNormalization)                                                
                                                                 
 activation_7 (Activation)   (None, 8, 8, 64)          0         
                                                                 
 flatten_1 (Flatten)         (None, 4096)              0         
                                                                 
 dense_1 (Dense)             (None, 2541)              10410477  
                                                                 
=================================================================
Total params: 10524077 (40.15 MB)
Trainable params: 10523565 (40.14 MB)
Non-trainable params: 512 (2.00 KB)
_________________________________________________________________
None
Model: "model_2"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d_8_input (InputLayer  [(None, 128, 128, 3)]     0         
 )                                                               
                                                                 
 conv2d_8 (Conv2D)           (None, 128, 128, 64)      1792      
                                                                 
 max_pooling2d_8 (MaxPoolin  (None, 64, 64, 64)        0         
 g2D)                                                            
                                                                 
 batch_normalization_8 (Bat  (None, 64, 64, 64)        256       
 chNormalization)                                                
                                                                 
 activation_8 (Activation)   (None, 64, 64, 64)        0         
                                                                 
 conv2d_9 (Conv2D)           (None, 64, 64, 64)        36928     
                                                                 
 max_pooling2d_9 (MaxPoolin  (None, 32, 32, 64)        0         
 g2D)                                                            
                                                                 
 batch_normalization_9 (Bat  (None, 32, 32, 64)        256       
 chNormalization)                                                
                                                                 
 activation_9 (Activation)   (None, 32, 32, 64)        0         
                                                                 
 conv2d_10 (Conv2D)          (None, 32, 32, 64)        36928     
                                                                 
 max_pooling2d_10 (MaxPooli  (None, 16, 16, 64)        0         
 ng2D)                                                           
                                                                 
 batch_normalization_10 (Ba  (None, 16, 16, 64)        256       
 tchNormalization)                                               
                                                                 
 activation_10 (Activation)  (None, 16, 16, 64)        0         
                                                                 
 conv2d_11 (Conv2D)          (None, 16, 16, 64)        36928     
                                                                 
 max_pooling2d_11 (MaxPooli  (None, 8, 8, 64)          0         
 ng2D)                                                           
                                                                 
 batch_normalization_11 (Ba  (None, 8, 8, 64)          256       
 tchNormalization)                                               
                                                                 
 activation_11 (Activation)  (None, 8, 8, 64)          0         
                                                                 
 flatten_2 (Flatten)         (None, 4096)              0         
                                                                 
 dense_2 (Dense)             (None, 2541)              10410477  
                                                                 
=================================================================
Total params: 10524077 (40.15 MB)
Trainable params: 10523565 (40.14 MB)
Non-trainable params: 512 (2.00 KB)
_________________________________________________________________
None
WARNING: Version mismatch detected: You are trying to connect to a simulator that might be incompatible with this API 
WARNING: Client API version     = 0.9.15 
WARNING: Simulator API version  = 0.9.14 
2023-12-30 01:12:24.350995: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904
2023-12-30 01:12:25.262343: I external/local_xla/xla/service/service.cc:168] XLA service 0x7fa650344340 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-12-30 01:12:25.262357: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 SUPER, Compute Capability 7.5
2023-12-30 01:12:25.265196: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1703916745.340169   12451 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
  0%|          | 0/1000 [00:00<?, ?episode/s]
Started episode 1 of 1000
Finished training first epoch.
Finished episode 1 of 1000
Saved model from episode 1. Count of epochs trained: 252
  0%|          | 1/1000 [03:56<65:33:24, 236.24s/episode]
Started episode 2 of 1000
Finished episode 2 of 1000
Saved model from episode 2. Count of epochs trained: 588
  0%|          | 2/1000 [07:51<65:21:29, 235.76s/episode]
Started episode 3 of 1000
Finished episode 3 of 1000
Saved model from episode 3. Count of epochs trained: 917
  0%|          | 3/1000 [11:45<65:00:58, 234.76s/episode]
Started episode 4 of 1000
Finished episode 4 of 1000
Saved model from episode 4. Count of epochs trained: 1242
  0%|          | 4/1000 [15:38<64:44:18, 233.99s/episode]
Started episode 5 of 1000
Finished episode 5 of 1000
Saved model from episode 5. Count of epochs trained: 1563
  0%|          | 5/1000 [19:30<64:29:11, 233.32s/episode]
Started episode 6 of 1000
Finished episode 6 of 1000
Count of epochs trained: 1881	Goal: 2340
Count of epochs trained: 1968	Goal: 2340
Count of epochs trained: 2056	Goal: 2340
Count of epochs trained: 2144	Goal: 2340
Count of epochs trained: 2232	Goal: 2340
Count of epochs trained: 2320	Goal: 2340
Saved model from episode 6. Count of epochs trained: 2408
  1%|          | 6/1000 [29:22<98:08:13, 355.43s/episode]
Started episode 7 of 1000
Finished episode 7 of 1000
Count of epochs trained: 2713	Goal: 3185
Count of epochs trained: 2801	Goal: 3185
Count of epochs trained: 2889	Goal: 3185
Count of epochs trained: 2976	Goal: 3185
Count of epochs trained: 3060	Goal: 3185
Count of epochs trained: 3148	Goal: 3185
Saved model from episode 7. Count of epochs trained: 3237
  1%|          | 7/1000 [39:13<119:16:35, 432.42s/episode]
Started episode 8 of 1000
Finished episode 8 of 1000
Count of epochs trained: 3262	Goal: 4014
Count of epochs trained: 3350	Goal: 4014
Count of epochs trained: 3439	Goal: 4014
Count of epochs trained: 3528	Goal: 4014
Count of epochs trained: 3615	Goal: 4014
Count of epochs trained: 3704	Goal: 4014
Count of epochs trained: 3792	Goal: 4014
Count of epochs trained: 3880	Goal: 4014
Count of epochs trained: 3966	Goal: 4014
Saved model from episode 8. Count of epochs trained: 4055
  1%|          | 8/1000 [48:33<130:18:51, 472.91s/episode]
Started episode 9 of 1000
Finished episode 9 of 1000
Count of epochs trained: 4152	Goal: 4832
Count of epochs trained: 4240	Goal: 4832
Count of epochs trained: 4329	Goal: 4832
Count of epochs trained: 4417	Goal: 4832
Count of epochs trained: 4506	Goal: 4832
Count of epochs trained: 4594	Goal: 4832
Count of epochs trained: 4678	Goal: 4832
Count of epochs trained: 4766	Goal: 4832
Saved model from episode 9. Count of epochs trained: 4854
  1%|          | 9/1000 [57:47<137:09:00, 498.22s/episode]
Started episode 10 of 1000
Finished episode 10 of 1000
Count of epochs trained: 4981	Goal: 5631
Count of epochs trained: 5065	Goal: 5631
Count of epochs trained: 5150	Goal: 5631
Count of epochs trained: 5238	Goal: 5631
Count of epochs trained: 5325	Goal: 5631
Count of epochs trained: 5413	Goal: 5631
Count of epochs trained: 5500	Goal: 5631
Count of epochs trained: 5588	Goal: 5631
Saved model from episode 10. Count of epochs trained: 5676
  1%|1         | 10/1000 [1:07:24<143:44:07, 522.67s/episode]
Started episode 11 of 1000
Finished episode 11 of 1000
Count of epochs trained: 5695	Goal: 6453
Count of epochs trained: 5783	Goal: 6453
Count of epochs trained: 5870	Goal: 6453
Count of epochs trained: 5957	Goal: 6453
Count of epochs trained: 6045	Goal: 6453
Count of epochs trained: 6133	Goal: 6453
Count of epochs trained: 6221	Goal: 6453
Count of epochs trained: 6309	Goal: 6453
Count of epochs trained: 6397	Goal: 6453
Saved model from episode 11. Count of epochs trained: 6485
  1%|1         | 11/1000 [1:16:41<146:26:15, 533.04s/episode]
Started episode 12 of 1000
Finished episode 12 of 1000
Count of epochs trained: 6630	Goal: 7262
Count of epochs trained: 6718	Goal: 7262
Count of epochs trained: 6807	Goal: 7262
Count of epochs trained: 6894	Goal: 7262
Count of epochs trained: 6983	Goal: 7262
Count of epochs trained: 7070	Goal: 7262
Count of epochs trained: 7158	Goal: 7262
Count of epochs trained: 7246	Goal: 7262
Saved model from episode 12. Count of epochs trained: 7336
  1%|1         | 12/1000 [1:26:29<150:54:57, 549.90s/episode]
Started episode 13 of 1000
Finished episode 13 of 1000
Count of epochs trained: 7341	Goal: 8113
Count of epochs trained: 7429	Goal: 8113
Count of epochs trained: 7518	Goal: 8113
Count of epochs trained: 7606	Goal: 8113
Count of epochs trained: 7694	Goal: 8113
Count of epochs trained: 7782	Goal: 8113
Count of epochs trained: 7870	Goal: 8113
Count of epochs trained: 7958	Goal: 8113
Count of epochs trained: 8045	Goal: 8113
Saved model from episode 13. Count of epochs trained: 8134
  1%|1         | 13/1000 [1:35:34<150:23:30, 548.54s/episode]
Started episode 14 of 1000
Finished episode 14 of 1000
Count of epochs trained: 8142	Goal: 8911
Count of epochs trained: 8230	Goal: 8911
Count of epochs trained: 8318	Goal: 8911
Count of epochs trained: 8406	Goal: 8911
Count of epochs trained: 8494	Goal: 8911
Count of epochs trained: 8582	Goal: 8911
Count of epochs trained: 8669	Goal: 8911
Count of epochs trained: 8757	Goal: 8911
Count of epochs trained: 8845	Goal: 8911
Saved model from episode 14. Count of epochs trained: 8933
  1%|1         | 14/1000 [1:44:42<150:07:49, 548.14s/episode]
Started episode 15 of 1000
Finished episode 15 of 1000
Count of epochs trained: 9027	Goal: 9710
Count of epochs trained: 9115	Goal: 9710
Count of epochs trained: 9202	Goal: 9710
Count of epochs trained: 9290	Goal: 9710
Count of epochs trained: 9377	Goal: 9710
Count of epochs trained: 9465	Goal: 9710
Count of epochs trained: 9552	Goal: 9710
Count of epochs trained: 9640	Goal: 9710
Saved model from episode 15. Count of epochs trained: 9729
  2%|1         | 15/1000 [1:53:52<150:09:52, 548.82s/episode]
Started episode 16 of 1000
Finished episode 16 of 1000
Count of epochs trained: 9733	Goal: 10506
Count of epochs trained: 9821	Goal: 10506
Count of epochs trained: 9908	Goal: 10506
Count of epochs trained: 9997	Goal: 10506
Count of epochs trained: 10084	Goal: 10506
Count of epochs trained: 10172	Goal: 10506
Count of epochs trained: 10259	Goal: 10506
Count of epochs trained: 10346	Goal: 10506
Count of epochs trained: 10434	Goal: 10506
Saved model from episode 16. Count of epochs trained: 10522
  2%|1         | 16/1000 [2:02:57<149:39:54, 547.56s/episode]
Started episode 17 of 1000
Finished episode 17 of 1000
Count of epochs trained: 10528	Goal: 11299
Count of epochs trained: 10616	Goal: 11299
Count of epochs trained: 10704	Goal: 11299
Count of epochs trained: 10791	Goal: 11299
Count of epochs trained: 10879	Goal: 11299
Count of epochs trained: 10966	Goal: 11299
Count of epochs trained: 11053	Goal: 11299
Count of epochs trained: 11141	Goal: 11299
Count of epochs trained: 11229	Goal: 11299
Saved model from episode 17. Count of epochs trained: 11317
  2%|1         | 17/1000 [2:12:02<149:21:37, 547.00s/episode]
Started episode 18 of 1000
Finished episode 18 of 1000
Count of epochs trained: 11329	Goal: 12094
Count of epochs trained: 11416	Goal: 12094
Count of epochs trained: 11504	Goal: 12094
Count of epochs trained: 11592	Goal: 12094
Count of epochs trained: 11680	Goal: 12094
Count of epochs trained: 11767	Goal: 12094
Count of epochs trained: 11855	Goal: 12094
Count of epochs trained: 11942	Goal: 12094
Count of epochs trained: 12029	Goal: 12094
Saved model from episode 18. Count of epochs trained: 12118
  2%|1         | 18/1000 [2:21:12<149:27:03, 547.89s/episode]
Started episode 19 of 1000
Finished episode 19 of 1000
Count of epochs trained: 12225	Goal: 12895
Count of epochs trained: 12307	Goal: 12895
Count of epochs trained: 12394	Goal: 12895
Count of epochs trained: 12481	Goal: 12895
Count of epochs trained: 12569	Goal: 12895
Count of epochs trained: 12655	Goal: 12895
Count of epochs trained: 12743	Goal: 12895
Count of epochs trained: 12830	Goal: 12895
Saved model from episode 19. Count of epochs trained: 12919
  2%|1         | 19/1000 [2:30:37<150:38:25, 552.81s/episode]
Started episode 20 of 1000
Finished episode 20 of 1000
Count of epochs trained: 12928	Goal: 13696
Count of epochs trained: 13016	Goal: 13696
Count of epochs trained: 13103	Goal: 13696
Count of epochs trained: 13191	Goal: 13696
Count of epochs trained: 13279	Goal: 13696
Count of epochs trained: 13365	Goal: 13696
Count of epochs trained: 13452	Goal: 13696
Count of epochs trained: 13540	Goal: 13696
Count of epochs trained: 13629	Goal: 13696
Saved model from episode 20. Count of epochs trained: 13717
  2%|2         | 20/1000 [2:39:45<150:10:07, 551.64s/episode]
Started episode 21 of 1000
Finished episode 21 of 1000
Count of epochs trained: 13723	Goal: 14494
Count of epochs trained: 13812	Goal: 14494
Count of epochs trained: 13900	Goal: 14494
Count of epochs trained: 13989	Goal: 14494
Count of epochs trained: 14077	Goal: 14494
Count of epochs trained: 14165	Goal: 14494
Count of epochs trained: 14253	Goal: 14494
Count of epochs trained: 14342	Goal: 14494
Count of epochs trained: 14430	Goal: 14494
Saved model from episode 21. Count of epochs trained: 14519
  2%|2         | 21/1000 [2:48:52<149:35:09, 550.06s/episode]
Started episode 22 of 1000
Finished episode 22 of 1000
Count of epochs trained: 14548	Goal: 15296
Count of epochs trained: 14636	Goal: 15296
Count of epochs trained: 14723	Goal: 15296
Count of epochs trained: 14812	Goal: 15296
Count of epochs trained: 14900	Goal: 15296
Count of epochs trained: 14988	Goal: 15296
Count of epochs trained: 15074	Goal: 15296
Count of epochs trained: 15161	Goal: 15296
Count of epochs trained: 15249	Goal: 15296
Saved model from episode 22. Count of epochs trained: 15338
  2%|2         | 22/1000 [2:58:16<150:34:23, 554.26s/episode]
Started episode 23 of 1000
Finished episode 23 of 1000
Count of epochs trained: 15344	Goal: 16115
Count of epochs trained: 15432	Goal: 16115
Count of epochs trained: 15520	Goal: 16115
Count of epochs trained: 15608	Goal: 16115
Count of epochs trained: 15696	Goal: 16115
Count of epochs trained: 15784	Goal: 16115
Count of epochs trained: 15871	Goal: 16115
Count of epochs trained: 15958	Goal: 16115
Count of epochs trained: 16046	Goal: 16115
Saved model from episode 23. Count of epochs trained: 16134
  2%|2         | 23/1000 [3:07:23<149:48:17, 551.99s/episode]
Started episode 24 of 1000
Finished episode 24 of 1000
Count of epochs trained: 16141	Goal: 16911
Count of epochs trained: 16229	Goal: 16911
Count of epochs trained: 16316	Goal: 16911
Count of epochs trained: 16404	Goal: 16911
Count of epochs trained: 16492	Goal: 16911
Count of epochs trained: 16579	Goal: 16911
Count of epochs trained: 16667	Goal: 16911
Count of epochs trained: 16754	Goal: 16911
Count of epochs trained: 16842	Goal: 16911
Saved model from episode 24. Count of epochs trained: 16930
  2%|2         | 24/1000 [3:16:29<149:13:23, 550.41s/episode]
Started episode 25 of 1000
Finished episode 25 of 1000
Count of epochs trained: 16938	Goal: 17707
Count of epochs trained: 17025	Goal: 17707
Count of epochs trained: 17112	Goal: 17707
Count of epochs trained: 17200	Goal: 17707
Count of epochs trained: 17288	Goal: 17707
Count of epochs trained: 17375	Goal: 17707
Count of epochs trained: 17462	Goal: 17707
Count of epochs trained: 17550	Goal: 17707
Count of epochs trained: 17638	Goal: 17707
Saved model from episode 25. Count of epochs trained: 17726
  2%|2         | 25/1000 [3:25:37<148:48:23, 549.44s/episode]
Started episode 26 of 1000
Finished episode 26 of 1000
Count of epochs trained: 17734	Goal: 18503
Count of epochs trained: 17821	Goal: 18503
Count of epochs trained: 17909	Goal: 18503
Count of epochs trained: 17997	Goal: 18503
Count of epochs trained: 18085	Goal: 18503
Count of epochs trained: 18173	Goal: 18503
Count of epochs trained: 18262	Goal: 18503
Count of epochs trained: 18350	Goal: 18503
Count of epochs trained: 18438	Goal: 18503
Saved model from episode 26. Count of epochs trained: 18527
  3%|2         | 26/1000 [3:34:43<148:26:23, 548.65s/episode]
Started episode 27 of 1000
Finished episode 27 of 1000
Count of epochs trained: 18823	Goal: 19304
Count of epochs trained: 18911	Goal: 19304
Count of epochs trained: 18999	Goal: 19304
Count of epochs trained: 19087	Goal: 19304
Count of epochs trained: 19175	Goal: 19304
Count of epochs trained: 19263	Goal: 19304
Saved model from episode 27. Count of epochs trained: 19351
  3%|2         | 27/1000 [3:44:30<151:21:38, 560.02s/episode]
Started episode 28 of 1000
Finished episode 28 of 1000
Count of epochs trained: 19646	Goal: 20128
Count of epochs trained: 19734	Goal: 20128
Count of epochs trained: 19822	Goal: 20128
Count of epochs trained: 19910	Goal: 20128
Count of epochs trained: 19997	Goal: 20128
Count of epochs trained: 20085	Goal: 20128
Saved model from episode 28. Count of epochs trained: 20173
  3%|2         | 28/1000 [3:54:16<153:19:09, 567.85s/episode]
Started episode 29 of 1000
Finished episode 29 of 1000
Count of epochs trained: 20341	Goal: 20950
Count of epochs trained: 20429	Goal: 20950
Count of epochs trained: 20516	Goal: 20950
Count of epochs trained: 20604	Goal: 20950
Count of epochs trained: 20692	Goal: 20950
Count of epochs trained: 20780	Goal: 20950
Count of epochs trained: 20868	Goal: 20950
Saved model from episode 29. Count of epochs trained: 20956
  3%|2         | 29/1000 [4:03:26<151:43:39, 562.53s/episode]
Started episode 30 of 1000
  3%|2         | 29/1000 [4:04:53<136:39:46, 506.68s/episode]
Error message: 'Failed to add concrete function \'b\'__inference_predict_function_76357216\'\' to object-based SavedModel as it captures tensor <tf.Tensor: shape=(), dtype=resource, value=<ResourceHandle(name="Variable/31", device="/job:localhost/replica:0/task:0/device:GPU:0", container="Anonymous", type="tensorflow::Var", dtype and shapes : "[ DType enum: 9, Shape: [] ]")>> which is unsupported or not reachable from root. One reason could be that a stateful object or a variable that the function depends on is not assigned to an attribute of the serialized trackable object (see SaveTest.test_captures_unreachable_variable).'
Error during episode 30
2023-12-30 05:17:52.243444: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-12-30 05:17:52.265278: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2023-12-30 05:17:52.265297: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2023-12-30 05:17:52.265838: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2023-12-30 05:17:52.269152: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-12-30 05:17:52.670312: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-12-30 05:17:52.979909: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-12-30 05:17:53.008264: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-12-30 05:17:53.008469: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-12-30 05:17:53.011496: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-12-30 05:17:53.011796: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-12-30 05:17:53.011999: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-12-30 05:17:53.729573: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-12-30 05:17:53.729704: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-12-30 05:17:53.729800: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-12-30 05:17:53.729909: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4422 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 SUPER, pci bus id: 0000:02:00.0, compute capability: 7.5
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d_input (InputLayer)   [(None, 128, 128, 3)]     0         
                                                                 
 conv2d (Conv2D)             (None, 128, 128, 64)      1792      
                                                                 
 max_pooling2d (MaxPooling2  (None, 64, 64, 64)        0         
 D)                                                              
                                                                 
 batch_normalization (Batch  (None, 64, 64, 64)        256       
 Normalization)                                                  
                                                                 
 activation (Activation)     (None, 64, 64, 64)        0         
                                                                 
 conv2d_1 (Conv2D)           (None, 64, 64, 64)        36928     
                                                                 
 max_pooling2d_1 (MaxPoolin  (None, 32, 32, 64)        0         
 g2D)                                                            
                                                                 
 batch_normalization_1 (Bat  (None, 32, 32, 64)        256       
 chNormalization)                                                
                                                                 
 activation_1 (Activation)   (None, 32, 32, 64)        0         
                                                                 
 conv2d_2 (Conv2D)           (None, 32, 32, 64)        36928     
                                                                 
 max_pooling2d_2 (MaxPoolin  (None, 16, 16, 64)        0         
 g2D)                                                            
                                                                 
 batch_normalization_2 (Bat  (None, 16, 16, 64)        256       
 chNormalization)                                                
                                                                 
 activation_2 (Activation)   (None, 16, 16, 64)        0         
                                                                 
 conv2d_3 (Conv2D)           (None, 16, 16, 64)        36928     
                                                                 
 max_pooling2d_3 (MaxPoolin  (None, 8, 8, 64)          0         
 g2D)                                                            
                                                                 
 batch_normalization_3 (Bat  (None, 8, 8, 64)          256       
 chNormalization)                                                
                                                                 
 activation_3 (Activation)   (None, 8, 8, 64)          0         
                                                                 
 flatten (Flatten)           (None, 4096)              0         
                                                                 
 dense (Dense)               (None, 2541)              10410477  
                                                                 
=================================================================
Total params: 10524077 (40.15 MB)
Trainable params: 10523565 (40.14 MB)
Non-trainable params: 512 (2.00 KB)
_________________________________________________________________
None
Model: "model_1"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d_4_input (InputLayer  [(None, 128, 128, 3)]     0         
 )                                                               
                                                                 
 conv2d_4 (Conv2D)           (None, 128, 128, 64)      1792      
                                                                 
 max_pooling2d_4 (MaxPoolin  (None, 64, 64, 64)        0         
 g2D)                                                            
                                                                 
 batch_normalization_4 (Bat  (None, 64, 64, 64)        256       
 chNormalization)                                                
                                                                 
 activation_4 (Activation)   (None, 64, 64, 64)        0         
                                                                 
 conv2d_5 (Conv2D)           (None, 64, 64, 64)        36928     
                                                                 
 max_pooling2d_5 (MaxPoolin  (None, 32, 32, 64)        0         
 g2D)                                                            
                                                                 
 batch_normalization_5 (Bat  (None, 32, 32, 64)        256       
 chNormalization)                                                
                                                                 
 activation_5 (Activation)   (None, 32, 32, 64)        0         
                                                                 
 conv2d_6 (Conv2D)           (None, 32, 32, 64)        36928     
                                                                 
 max_pooling2d_6 (MaxPoolin  (None, 16, 16, 64)        0         
 g2D)                                                            
                                                                 
 batch_normalization_6 (Bat  (None, 16, 16, 64)        256       
 chNormalization)                                                
                                                                 
 activation_6 (Activation)   (None, 16, 16, 64)        0         
                                                                 
 conv2d_7 (Conv2D)           (None, 16, 16, 64)        36928     
                                                                 
 max_pooling2d_7 (MaxPoolin  (None, 8, 8, 64)          0         
 g2D)                                                            
                                                                 
 batch_normalization_7 (Bat  (None, 8, 8, 64)          256       
 chNormalization)                                                
                                                                 
 activation_7 (Activation)   (None, 8, 8, 64)          0         
                                                                 
 flatten_1 (Flatten)         (None, 4096)              0         
                                                                 
 dense_1 (Dense)             (None, 2541)              10410477  
                                                                 
=================================================================
Total params: 10524077 (40.15 MB)
Trainable params: 10523565 (40.14 MB)
Non-trainable params: 512 (2.00 KB)
_________________________________________________________________
None
Model: "model_2"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d_8_input (InputLayer  [(None, 128, 128, 3)]     0         
 )                                                               
                                                                 
 conv2d_8 (Conv2D)           (None, 128, 128, 64)      1792      
                                                                 
 max_pooling2d_8 (MaxPoolin  (None, 64, 64, 64)        0         
 g2D)                                                            
                                                                 
 batch_normalization_8 (Bat  (None, 64, 64, 64)        256       
 chNormalization)                                                
                                                                 
 activation_8 (Activation)   (None, 64, 64, 64)        0         
                                                                 
 conv2d_9 (Conv2D)           (None, 64, 64, 64)        36928     
                                                                 
 max_pooling2d_9 (MaxPoolin  (None, 32, 32, 64)        0         
 g2D)                                                            
                                                                 
 batch_normalization_9 (Bat  (None, 32, 32, 64)        256       
 chNormalization)                                                
                                                                 
 activation_9 (Activation)   (None, 32, 32, 64)        0         
                                                                 
 conv2d_10 (Conv2D)          (None, 32, 32, 64)        36928     
                                                                 
 max_pooling2d_10 (MaxPooli  (None, 16, 16, 64)        0         
 ng2D)                                                           
                                                                 
 batch_normalization_10 (Ba  (None, 16, 16, 64)        256       
 tchNormalization)                                               
                                                                 
 activation_10 (Activation)  (None, 16, 16, 64)        0         
                                                                 
 conv2d_11 (Conv2D)          (None, 16, 16, 64)        36928     
                                                                 
 max_pooling2d_11 (MaxPooli  (None, 8, 8, 64)          0         
 ng2D)                                                           
                                                                 
 batch_normalization_11 (Ba  (None, 8, 8, 64)          256       
 tchNormalization)                                               
                                                                 
 activation_11 (Activation)  (None, 8, 8, 64)          0         
                                                                 
 flatten_2 (Flatten)         (None, 4096)              0         
                                                                 
 dense_2 (Dense)             (None, 2541)              10410477  
                                                                 
=================================================================
Total params: 10524077 (40.15 MB)
Trainable params: 10523565 (40.14 MB)
Non-trainable params: 512 (2.00 KB)
_________________________________________________________________
None
Models in tmp ['tmp/001.252.model', 'tmp/002.587.model', 'tmp/003.916.model', 'tmp/004.1241.model', 'tmp/005.1562.model', 'tmp/006.2408.model', 'tmp/007.3237.model', 'tmp/008.4054.model', 'tmp/009.4853.model', 'tmp/010.5676.model', 'tmp/011.6484.model', 'tmp/012.7335.model', 'tmp/013.8133.model', 'tmp/014.8932.model', 'tmp/015.9728.model', 'tmp/016.10521.model', 'tmp/017.11317.model', 'tmp/018.12117.model', 'tmp/019.12918.model', 'tmp/020.13717.model', 'tmp/021.14518.model', 'tmp/022.15337.model', 'tmp/023.16134.model', 'tmp/024.16930.model', 'tmp/025.17726.model', 'tmp/026.18526.model', 'tmp/027.19351.model', 'tmp/028.20173.model', 'tmp/029.20956.model']
Load model tmp/029.20956.model
Leftover images from failed episode: ['_out_16rl_custom2/030_037919.png', '_out_16rl_custom2/030_037920.png', '_out_16rl_custom2/030_037921.png', '_out_16rl_custom2/030_037922.png', '_out_16rl_custom2/030_037923.png', '_out_16rl_custom2/030_037924.png', '_out_16rl_custom2/030_037925.png', '_out_16rl_custom2/030_037927.png', '_out_16rl_custom2/030_037928.png', '_out_16rl_custom2/030_037929.png', '_out_16rl_custom2/030_037930.png', '_out_16rl_custom2/030_037931.png', '_out_16rl_custom2/030_037932.png', '_out_16rl_custom2/030_037934.png', '_out_16rl_custom2/030_037935.png', '_out_16rl_custom2/030_037936.png', '_out_16rl_custom2/030_037938.png', '_out_16rl_custom2/030_037939.png', '_out_16rl_custom2/030_037940.png', '_out_16rl_custom2/030_037941.png', '_out_16rl_custom2/030_037942.png', '_out_16rl_custom2/030_037944.png', '_out_16rl_custom2/030_037945.png', '_out_16rl_custom2/030_037947.png', '_out_16rl_custom2/030_037949.png', '_out_16rl_custom2/030_037950.png', '_out_16rl_custom2/030_037951.png', '_out_16rl_custom2/030_037952.png', '_out_16rl_custom2/030_037953.png', '_out_16rl_custom2/030_037954.png', '_out_16rl_custom2/030_037955.png', '_out_16rl_custom2/030_037956.png', '_out_16rl_custom2/030_037957.png', '_out_16rl_custom2/030_037959.png', '_out_16rl_custom2/030_037960.png', '_out_16rl_custom2/030_037961.png', '_out_16rl_custom2/030_037963.png', '_out_16rl_custom2/030_037964.png', '_out_16rl_custom2/030_037965.png', '_out_16rl_custom2/030_037966.png', '_out_16rl_custom2/030_037967.png', '_out_16rl_custom2/030_037969.png', '_out_16rl_custom2/030_037970.png', '_out_16rl_custom2/030_037971.png', '_out_16rl_custom2/030_037972.png', '_out_16rl_custom2/030_037974.png', '_out_16rl_custom2/030_037975.png', '_out_16rl_custom2/030_037977.png', '_out_16rl_custom2/030_037979.png', '_out_16rl_custom2/030_037980.png', '_out_16rl_custom2/030_037981.png', '_out_16rl_custom2/030_037983.png', '_out_16rl_custom2/030_037984.png', '_out_16rl_custom2/030_037985.png', '_out_16rl_custom2/030_037986.png', '_out_16rl_custom2/030_037987.png', '_out_16rl_custom2/030_037988.png', '_out_16rl_custom2/030_037990.png', '_out_16rl_custom2/030_037991.png', '_out_16rl_custom2/030_037992.png', '_out_16rl_custom2/030_037993.png', '_out_16rl_custom2/030_037994.png', '_out_16rl_custom2/030_037995.png', '_out_16rl_custom2/030_037997.png', '_out_16rl_custom2/030_037998.png', '_out_16rl_custom2/030_037999.png', '_out_16rl_custom2/030_038000.png', '_out_16rl_custom2/030_038001.png', '_out_16rl_custom2/030_038002.png', '_out_16rl_custom2/030_038003.png', '_out_16rl_custom2/030_038004.png', '_out_16rl_custom2/030_038006.png', '_out_16rl_custom2/030_038007.png', '_out_16rl_custom2/030_038008.png', '_out_16rl_custom2/030_038009.png', '_out_16rl_custom2/030_038011.png', '_out_16rl_custom2/030_038013.png', '_out_16rl_custom2/030_038014.png', '_out_16rl_custom2/030_038016.png', '_out_16rl_custom2/030_038018.png', '_out_16rl_custom2/030_038019.png', '_out_16rl_custom2/030_038020.png', '_out_16rl_custom2/030_038021.png', '_out_16rl_custom2/030_038022.png', '_out_16rl_custom2/030_038023.png', '_out_16rl_custom2/030_038024.png', '_out_16rl_custom2/030_038025.png', '_out_16rl_custom2/030_038026.png', '_out_16rl_custom2/030_038027.png', '_out_16rl_custom2/030_038028.png', '_out_16rl_custom2/030_038029.png', '_out_16rl_custom2/030_038031.png', '_out_16rl_custom2/030_038032.png', '_out_16rl_custom2/030_038033.png', '_out_16rl_custom2/030_038034.png', '_out_16rl_custom2/030_038035.png', '_out_16rl_custom2/030_038036.png', '_out_16rl_custom2/030_038037.png', '_out_16rl_custom2/030_038039.png', '_out_16rl_custom2/030_038040.png', '_out_16rl_custom2/030_038041.png', '_out_16rl_custom2/030_038042.png', '_out_16rl_custom2/030_038043.png', '_out_16rl_custom2/030_038045.png', '_out_16rl_custom2/030_038046.png', '_out_16rl_custom2/030_038047.png', '_out_16rl_custom2/030_038048.png', '_out_16rl_custom2/030_038049.png', '_out_16rl_custom2/030_038050.png', '_out_16rl_custom2/030_038051.png', '_out_16rl_custom2/030_038053.png', '_out_16rl_custom2/030_038054.png', '_out_16rl_custom2/030_038056.png', '_out_16rl_custom2/030_038057.png', '_out_16rl_custom2/030_038058.png', '_out_16rl_custom2/030_038059.png', '_out_16rl_custom2/030_038060.png', '_out_16rl_custom2/030_038061.png', '_out_16rl_custom2/030_038063.png', '_out_16rl_custom2/030_038064.png', '_out_16rl_custom2/030_038066.png', '_out_16rl_custom2/030_038067.png', '_out_16rl_custom2/030_038068.png', '_out_16rl_custom2/030_038069.png', '_out_16rl_custom2/030_038071.png', '_out_16rl_custom2/030_038072.png', '_out_16rl_custom2/030_038073.png', '_out_16rl_custom2/030_038074.png', '_out_16rl_custom2/030_038075.png', '_out_16rl_custom2/030_038077.png', '_out_16rl_custom2/030_038078.png', '_out_16rl_custom2/030_038079.png', '_out_16rl_custom2/030_038080.png', '_out_16rl_custom2/030_038081.png', '_out_16rl_custom2/030_038082.png', '_out_16rl_custom2/030_038083.png', '_out_16rl_custom2/030_038084.png', '_out_16rl_custom2/030_038086.png', '_out_16rl_custom2/030_038088.png', '_out_16rl_custom2/030_038089.png', '_out_16rl_custom2/030_038091.png', '_out_16rl_custom2/030_038092.png', '_out_16rl_custom2/030_038093.png', '_out_16rl_custom2/030_038094.png', '_out_16rl_custom2/030_038095.png', '_out_16rl_custom2/030_038096.png', '_out_16rl_custom2/030_038097.png', '_out_16rl_custom2/030_038099.png', '_out_16rl_custom2/030_038100.png', '_out_16rl_custom2/030_038101.png', '_out_16rl_custom2/030_038102.png', '_out_16rl_custom2/030_038103.png', '_out_16rl_custom2/030_038104.png', '_out_16rl_custom2/030_038106.png', '_out_16rl_custom2/030_038107.png', '_out_16rl_custom2/030_038108.png', '_out_16rl_custom2/030_038109.png', '_out_16rl_custom2/030_038110.png', '_out_16rl_custom2/030_038111.png', '_out_16rl_custom2/030_038113.png', '_out_16rl_custom2/030_038114.png', '_out_16rl_custom2/030_038115.png', '_out_16rl_custom2/030_038116.png', '_out_16rl_custom2/030_038117.png', '_out_16rl_custom2/030_038118.png', '_out_16rl_custom2/030_038120.png', '_out_16rl_custom2/030_038122.png', '_out_16rl_custom2/030_038123.png', '_out_16rl_custom2/030_038125.png', '_out_16rl_custom2/030_038126.png', '_out_16rl_custom2/030_038127.png', '_out_16rl_custom2/030_038128.png', '_out_16rl_custom2/030_038129.png', '_out_16rl_custom2/030_038130.png', '_out_16rl_custom2/030_038131.png', '_out_16rl_custom2/030_038132.png', '_out_16rl_custom2/030_038134.png', '_out_16rl_custom2/030_038135.png', '_out_16rl_custom2/030_038136.png', '_out_16rl_custom2/030_038137.png', '_out_16rl_custom2/030_038138.png', '_out_16rl_custom2/030_038139.png', '_out_16rl_custom2/030_038140.png', '_out_16rl_custom2/030_038141.png', '_out_16rl_custom2/030_038142.png', '_out_16rl_custom2/030_038143.png', '_out_16rl_custom2/030_038144.png', '_out_16rl_custom2/030_038145.png', '_out_16rl_custom2/030_038146.png', '_out_16rl_custom2/030_038147.png', '_out_16rl_custom2/030_038148.png', '_out_16rl_custom2/030_038149.png', '_out_16rl_custom2/030_038150.png', '_out_16rl_custom2/030_038151.png', '_out_16rl_custom2/030_038152.png', '_out_16rl_custom2/030_038153.png', '_out_16rl_custom2/030_038154.png', '_out_16rl_custom2/030_038155.png', '_out_16rl_custom2/030_038156.png', '_out_16rl_custom2/030_038158.png', '_out_16rl_custom2/030_038159.png', '_out_16rl_custom2/030_038160.png', '_out_16rl_custom2/030_038161.png', '_out_16rl_custom2/030_038162.png', '_out_16rl_custom2/030_038163.png', '_out_16rl_custom2/030_038164.png', '_out_16rl_custom2/030_038165.png', '_out_16rl_custom2/030_038166.png', '_out_16rl_custom2/030_038167.png', '_out_16rl_custom2/030_038168.png', '_out_16rl_custom2/030_038170.png', '_out_16rl_custom2/030_038171.png', '_out_16rl_custom2/030_038172.png', '_out_16rl_custom2/030_038174.png', '_out_16rl_custom2/030_038175.png', '_out_16rl_custom2/030_038177.png', '_out_16rl_custom2/030_038178.png', '_out_16rl_custom2/030_038180.png', '_out_16rl_custom2/030_038181.png', '_out_16rl_custom2/030_038182.png', '_out_16rl_custom2/030_038183.png', '_out_16rl_custom2/030_038184.png', '_out_16rl_custom2/030_038185.png', '_out_16rl_custom2/030_038186.png', '_out_16rl_custom2/030_038188.png', '_out_16rl_custom2/030_038189.png', '_out_16rl_custom2/030_038190.png', '_out_16rl_custom2/030_038191.png', '_out_16rl_custom2/030_038192.png', '_out_16rl_custom2/030_038193.png', '_out_16rl_custom2/030_038194.png', '_out_16rl_custom2/030_038196.png', '_out_16rl_custom2/030_038197.png', '_out_16rl_custom2/030_038199.png', '_out_16rl_custom2/030_038201.png', '_out_16rl_custom2/030_038202.png', '_out_16rl_custom2/030_038203.png', '_out_16rl_custom2/030_038204.png', '_out_16rl_custom2/030_038205.png', '_out_16rl_custom2/030_038206.png', '_out_16rl_custom2/030_038207.png', '_out_16rl_custom2/030_038208.png', '_out_16rl_custom2/030_038209.png', '_out_16rl_custom2/030_038210.png', '_out_16rl_custom2/030_038212.png', '_out_16rl_custom2/030_038213.png', '_out_16rl_custom2/030_038214.png', '_out_16rl_custom2/030_038216.png', '_out_16rl_custom2/030_038217.png', '_out_16rl_custom2/030_038218.png', '_out_16rl_custom2/030_038219.png', '_out_16rl_custom2/030_038220.png', '_out_16rl_custom2/030_038221.png', '_out_16rl_custom2/030_038222.png', '_out_16rl_custom2/030_038223.png', '_out_16rl_custom2/030_038224.png', '_out_16rl_custom2/030_038225.png', '_out_16rl_custom2/030_038226.png', '_out_16rl_custom2/030_038227.png', '_out_16rl_custom2/030_038228.png', '_out_16rl_custom2/030_038230.png', '_out_16rl_custom2/030_038231.png', '_out_16rl_custom2/030_038232.png', '_out_16rl_custom2/030_038233.png', '_out_16rl_custom2/030_038234.png', '_out_16rl_custom2/030_038235.png', '_out_16rl_custom2/030_038236.png', '_out_16rl_custom2/030_038238.png', '_out_16rl_custom2/030_038239.png', '_out_16rl_custom2/030_038240.png', '_out_16rl_custom2/030_038241.png', '_out_16rl_custom2/030_038242.png', '_out_16rl_custom2/030_038244.png', '_out_16rl_custom2/030_038245.png', '_out_16rl_custom2/030_038246.png', '_out_16rl_custom2/030_038247.png', '_out_16rl_custom2/030_038248.png', '_out_16rl_custom2/030_038249.png', '_out_16rl_custom2/030_038250.png', '_out_16rl_custom2/030_038251.png', '_out_16rl_custom2/030_038252.png', '_out_16rl_custom2/030_038253.png', '_out_16rl_custom2/030_038254.png', '_out_16rl_custom2/030_038255.png', '_out_16rl_custom2/030_038256.png', '_out_16rl_custom2/030_038257.png', '_out_16rl_custom2/030_038259.png', '_out_16rl_custom2/030_038260.png', '_out_16rl_custom2/030_038261.png', '_out_16rl_custom2/030_038263.png', '_out_16rl_custom2/030_038264.png', '_out_16rl_custom2/030_038265.png', '_out_16rl_custom2/030_038267.png', '_out_16rl_custom2/030_038268.png', '_out_16rl_custom2/030_038269.png', '_out_16rl_custom2/030_038270.png', '_out_16rl_custom2/030_038271.png', '_out_16rl_custom2/030_038272.png', '_out_16rl_custom2/030_038273.png', '_out_16rl_custom2/030_038274.png', '_out_16rl_custom2/030_038275.png', '_out_16rl_custom2/030_038276.png', '_out_16rl_custom2/030_038277.png', '_out_16rl_custom2/030_038278.png', '_out_16rl_custom2/030_038279.png', '_out_16rl_custom2/030_038280.png', '_out_16rl_custom2/030_038281.png', '_out_16rl_custom2/030_038283.png', '_out_16rl_custom2/030_038284.png', '_out_16rl_custom2/030_038285.png', '_out_16rl_custom2/030_038286.png', '_out_16rl_custom2/030_038288.png', '_out_16rl_custom2/030_038289.png', '_out_16rl_custom2/030_038290.png', '_out_16rl_custom2/030_038291.png', '_out_16rl_custom2/030_038292.png', '_out_16rl_custom2/030_038293.png', '_out_16rl_custom2/030_038294.png', '_out_16rl_custom2/030_038295.png', '_out_16rl_custom2/030_038297.png', '_out_16rl_custom2/030_038299.png', '_out_16rl_custom2/030_038300.png', '_out_16rl_custom2/030_038301.png', '_out_16rl_custom2/030_038302.png', '_out_16rl_custom2/030_038304.png', '_out_16rl_custom2/030_038305.png', '_out_16rl_custom2/030_038306.png', '_out_16rl_custom2/030_038307.png', '_out_16rl_custom2/030_038308.png', '_out_16rl_custom2/030_038309.png', '_out_16rl_custom2/030_038310.png', '_out_16rl_custom2/030_038311.png', '_out_16rl_custom2/030_038313.png', '_out_16rl_custom2/030_038314.png', '_out_16rl_custom2/030_038315.png', '_out_16rl_custom2/030_038316.png', '_out_16rl_custom2/030_038317.png', '_out_16rl_custom2/030_038318.png', '_out_16rl_custom2/030_038319.png', '_out_16rl_custom2/030_038320.png', '_out_16rl_custom2/030_038321.png', '_out_16rl_custom2/030_038322.png', '_out_16rl_custom2/030_038324.png', '_out_16rl_custom2/030_038325.png', '_out_16rl_custom2/030_038326.png', '_out_16rl_custom2/030_038327.png', '_out_16rl_custom2/030_038328.png', '_out_16rl_custom2/030_038330.png', '_out_16rl_custom2/030_038331.png', '_out_16rl_custom2/030_038332.png', '_out_16rl_custom2/030_038333.png', '_out_16rl_custom2/030_038334.png', '_out_16rl_custom2/030_038335.png', '_out_16rl_custom2/030_038336.png', '_out_16rl_custom2/030_038337.png', '_out_16rl_custom2/030_038338.png', '_out_16rl_custom2/030_038339.png', '_out_16rl_custom2/030_038340.png', '_out_16rl_custom2/030_038341.png', '_out_16rl_custom2/030_038343.png', '_out_16rl_custom2/030_038344.png', '_out_16rl_custom2/030_038345.png', '_out_16rl_custom2/030_038346.png', '_out_16rl_custom2/030_038347.png', '_out_16rl_custom2/030_038348.png', '_out_16rl_custom2/030_038349.png', '_out_16rl_custom2/030_038350.png', '_out_16rl_custom2/030_038351.png', '_out_16rl_custom2/030_038352.png', '_out_16rl_custom2/030_038353.png', '_out_16rl_custom2/030_038355.png', '_out_16rl_custom2/030_038356.png', '_out_16rl_custom2/030_038357.png', '_out_16rl_custom2/030_038358.png', '_out_16rl_custom2/030_038359.png', '_out_16rl_custom2/030_038360.png', '_out_16rl_custom2/030_038361.png', '_out_16rl_custom2/030_038362.png', '_out_16rl_custom2/030_038363.png', '_out_16rl_custom2/030_038364.png', '_out_16rl_custom2/030_038366.png', '_out_16rl_custom2/030_038367.png', '_out_16rl_custom2/030_038369.png', '_out_16rl_custom2/030_038370.png', '_out_16rl_custom2/030_038372.png', '_out_16rl_custom2/030_038373.png', '_out_16rl_custom2/030_038375.png', '_out_16rl_custom2/030_038376.png', '_out_16rl_custom2/030_038377.png', '_out_16rl_custom2/030_038378.png', '_out_16rl_custom2/030_038379.png', '_out_16rl_custom2/030_038381.png', '_out_16rl_custom2/030_038382.png', '_out_16rl_custom2/030_038383.png', '_out_16rl_custom2/030_038385.png', '_out_16rl_custom2/030_038387.png', '_out_16rl_custom2/030_038388.png', '_out_16rl_custom2/030_038390.png', '_out_16rl_custom2/030_038391.png', '_out_16rl_custom2/030_038392.png', '_out_16rl_custom2/030_038393.png', '_out_16rl_custom2/030_038394.png', '_out_16rl_custom2/030_038396.png', '_out_16rl_custom2/030_038397.png', '_out_16rl_custom2/030_038398.png', '_out_16rl_custom2/030_038400.png', '_out_16rl_custom2/030_038401.png', '_out_16rl_custom2/030_038402.png', '_out_16rl_custom2/030_038403.png', '_out_16rl_custom2/030_038404.png', '_out_16rl_custom2/030_038405.png', '_out_16rl_custom2/030_038406.png', '_out_16rl_custom2/030_038407.png', '_out_16rl_custom2/030_038408.png', '_out_16rl_custom2/030_038410.png', '_out_16rl_custom2/030_038412.png', '_out_16rl_custom2/030_038413.png', '_out_16rl_custom2/030_038414.png', '_out_16rl_custom2/030_038415.png', '_out_16rl_custom2/030_038416.png', '_out_16rl_custom2/030_038418.png', '_out_16rl_custom2/030_038420.png', '_out_16rl_custom2/030_038421.png', '_out_16rl_custom2/030_038422.png', '_out_16rl_custom2/030_038423.png', '_out_16rl_custom2/030_038425.png', '_out_16rl_custom2/030_038427.png', '_out_16rl_custom2/030_038428.png', '_out_16rl_custom2/030_038429.png', '_out_16rl_custom2/030_038430.png', '_out_16rl_custom2/030_038432.png', '_out_16rl_custom2/030_038433.png', '_out_16rl_custom2/030_038434.png', '_out_16rl_custom2/030_038435.png', '_out_16rl_custom2/030_038436.png', '_out_16rl_custom2/030_038437.png', '_out_16rl_custom2/030_038438.png', '_out_16rl_custom2/030_038439.png', '_out_16rl_custom2/030_038440.png', '_out_16rl_custom2/030_038441.png', '_out_16rl_custom2/030_038442.png', '_out_16rl_custom2/030_038443.png', '_out_16rl_custom2/030_038444.png', '_out_16rl_custom2/030_038445.png', '_out_16rl_custom2/030_038446.png', '_out_16rl_custom2/030_038447.png', '_out_16rl_custom2/030_038448.png', '_out_16rl_custom2/030_038449.png', '_out_16rl_custom2/030_038450.png', '_out_16rl_custom2/030_038451.png', '_out_16rl_custom2/030_038452.png', '_out_16rl_custom2/030_038453.png', '_out_16rl_custom2/030_038455.png', '_out_16rl_custom2/030_038456.png', '_out_16rl_custom2/030_038457.png', '_out_16rl_custom2/030_038458.png', '_out_16rl_custom2/030_038459.png', '_out_16rl_custom2/030_038460.png', '_out_16rl_custom2/030_038461.png', '_out_16rl_custom2/030_038463.png', '_out_16rl_custom2/030_038464.png', '_out_16rl_custom2/030_038465.png', '_out_16rl_custom2/030_038466.png', '_out_16rl_custom2/030_038467.png', '_out_16rl_custom2/030_038468.png', '_out_16rl_custom2/030_038469.png', '_out_16rl_custom2/030_038471.png', '_out_16rl_custom2/030_038472.png', '_out_16rl_custom2/030_038473.png', '_out_16rl_custom2/030_038474.png', '_out_16rl_custom2/030_038475.png', '_out_16rl_custom2/030_038476.png', '_out_16rl_custom2/030_038477.png', '_out_16rl_custom2/030_038478.png', '_out_16rl_custom2/030_038479.png', '_out_16rl_custom2/030_038480.png', '_out_16rl_custom2/030_038481.png', '_out_16rl_custom2/030_038482.png', '_out_16rl_custom2/030_038483.png', '_out_16rl_custom2/030_038484.png', '_out_16rl_custom2/030_038485.png', '_out_16rl_custom2/030_038486.png', '_out_16rl_custom2/030_038487.png', '_out_16rl_custom2/030_038488.png', '_out_16rl_custom2/030_038489.png', '_out_16rl_custom2/030_038490.png', '_out_16rl_custom2/030_038491.png', '_out_16rl_custom2/030_038492.png', '_out_16rl_custom2/030_038493.png', '_out_16rl_custom2/030_038495.png', '_out_16rl_custom2/030_038496.png', '_out_16rl_custom2/030_038497.png', '_out_16rl_custom2/030_038498.png', '_out_16rl_custom2/030_038499.png', '_out_16rl_custom2/030_038500.png', '_out_16rl_custom2/030_038501.png', '_out_16rl_custom2/030_038502.png', '_out_16rl_custom2/030_038503.png', '_out_16rl_custom2/030_038505.png', '_out_16rl_custom2/030_038506.png', '_out_16rl_custom2/030_038508.png', '_out_16rl_custom2/030_038509.png', '_out_16rl_custom2/030_038510.png', '_out_16rl_custom2/030_038511.png', '_out_16rl_custom2/030_038512.png', '_out_16rl_custom2/030_038513.png', '_out_16rl_custom2/030_038514.png', '_out_16rl_custom2/030_038516.png', '_out_16rl_custom2/030_038517.png', '_out_16rl_custom2/030_038518.png', '_out_16rl_custom2/030_038519.png', '_out_16rl_custom2/030_038520.png', '_out_16rl_custom2/030_038521.png', '_out_16rl_custom2/030_038522.png', '_out_16rl_custom2/030_038523.png', '_out_16rl_custom2/030_038524.png', '_out_16rl_custom2/030_038526.png', '_out_16rl_custom2/030_038528.png', '_out_16rl_custom2/030_038529.png', '_out_16rl_custom2/030_038530.png', '_out_16rl_custom2/030_038531.png', '_out_16rl_custom2/030_038532.png', '_out_16rl_custom2/030_038533.png', '_out_16rl_custom2/030_038535.png', '_out_16rl_custom2/030_038536.png', '_out_16rl_custom2/030_038537.png', '_out_16rl_custom2/030_038538.png', '_out_16rl_custom2/030_038540.png', '_out_16rl_custom2/030_038541.png', '_out_16rl_custom2/030_038542.png', '_out_16rl_custom2/030_038543.png', '_out_16rl_custom2/030_038544.png', '_out_16rl_custom2/030_038546.png', '_out_16rl_custom2/030_038548.png', '_out_16rl_custom2/030_038549.png', '_out_16rl_custom2/030_038550.png', '_out_16rl_custom2/030_038552.png', '_out_16rl_custom2/030_038553.png', '_out_16rl_custom2/030_038555.png', '_out_16rl_custom2/030_038556.png', '_out_16rl_custom2/030_038557.png', '_out_16rl_custom2/030_038558.png', '_out_16rl_custom2/030_038559.png', '_out_16rl_custom2/030_038560.png', '_out_16rl_custom2/030_038561.png', '_out_16rl_custom2/030_038562.png', '_out_16rl_custom2/030_038564.png', '_out_16rl_custom2/030_038565.png', '_out_16rl_custom2/030_038566.png', '_out_16rl_custom2/030_038568.png', '_out_16rl_custom2/030_038570.png', '_out_16rl_custom2/030_038571.png', '_out_16rl_custom2/030_038573.png', '_out_16rl_custom2/030_038574.png', '_out_16rl_custom2/030_038575.png', '_out_16rl_custom2/030_038576.png', '_out_16rl_custom2/030_038577.png', '_out_16rl_custom2/030_038578.png', '_out_16rl_custom2/030_038579.png', '_out_16rl_custom2/030_038580.png', '_out_16rl_custom2/030_038581.png', '_out_16rl_custom2/030_038583.png', '_out_16rl_custom2/030_038585.png', '_out_16rl_custom2/030_038586.png', '_out_16rl_custom2/030_038587.png', '_out_16rl_custom2/030_038588.png', '_out_16rl_custom2/030_038590.png', '_out_16rl_custom2/030_038591.png', '_out_16rl_custom2/030_038593.png', '_out_16rl_custom2/030_038594.png', '_out_16rl_custom2/030_038596.png', '_out_16rl_custom2/030_038597.png', '_out_16rl_custom2/030_038598.png', '_out_16rl_custom2/030_038599.png', '_out_16rl_custom2/030_038600.png', '_out_16rl_custom2/030_038601.png', '_out_16rl_custom2/030_038603.png', '_out_16rl_custom2/030_038604.png', '_out_16rl_custom2/030_038605.png', '_out_16rl_custom2/030_038606.png', '_out_16rl_custom2/030_038607.png', '_out_16rl_custom2/030_038608.png', '_out_16rl_custom2/030_038610.png', '_out_16rl_custom2/030_038611.png', '_out_16rl_custom2/030_038613.png', '_out_16rl_custom2/030_038615.png', '_out_16rl_custom2/030_038616.png', '_out_16rl_custom2/030_038617.png', '_out_16rl_custom2/030_038618.png', '_out_16rl_custom2/030_038620.png', '_out_16rl_custom2/030_038621.png', '_out_16rl_custom2/030_038622.png', '_out_16rl_custom2/030_038624.png', '_out_16rl_custom2/030_038625.png', '_out_16rl_custom2/030_038626.png', '_out_16rl_custom2/030_038627.png', '_out_16rl_custom2/030_038628.png', '_out_16rl_custom2/030_038629.png', '_out_16rl_custom2/030_038630.png', '_out_16rl_custom2/030_038631.png', '_out_16rl_custom2/030_038632.png', '_out_16rl_custom2/030_038633.png', '_out_16rl_custom2/030_038634.png', '_out_16rl_custom2/030_038636.png', '_out_16rl_custom2/030_038637.png', '_out_16rl_custom2/030_038638.png', '_out_16rl_custom2/030_038639.png', '_out_16rl_custom2/030_038640.png', '_out_16rl_custom2/030_038641.png', '_out_16rl_custom2/030_038642.png', '_out_16rl_custom2/030_038643.png', '_out_16rl_custom2/030_038644.png', '_out_16rl_custom2/030_038645.png', '_out_16rl_custom2/030_038647.png', '_out_16rl_custom2/030_038648.png', '_out_16rl_custom2/030_038649.png', '_out_16rl_custom2/030_038650.png', '_out_16rl_custom2/030_038652.png', '_out_16rl_custom2/030_038653.png', '_out_16rl_custom2/030_038655.png', '_out_16rl_custom2/030_038656.png', '_out_16rl_custom2/030_038657.png', '_out_16rl_custom2/030_038659.png', '_out_16rl_custom2/030_038660.png', '_out_16rl_custom2/030_038661.png', '_out_16rl_custom2/030_038662.png', '_out_16rl_custom2/030_038663.png', '_out_16rl_custom2/030_038664.png', '_out_16rl_custom2/030_038665.png', '_out_16rl_custom2/030_038666.png', '_out_16rl_custom2/030_038667.png', '_out_16rl_custom2/030_038669.png', '_out_16rl_custom2/030_038670.png', '_out_16rl_custom2/030_038671.png', '_out_16rl_custom2/030_038673.png', '_out_16rl_custom2/030_038674.png', '_out_16rl_custom2/030_038675.png', '_out_16rl_custom2/030_038676.png', '_out_16rl_custom2/030_038677.png', '_out_16rl_custom2/030_038678.png', '_out_16rl_custom2/030_038679.png', '_out_16rl_custom2/030_038680.png', '_out_16rl_custom2/030_038682.png', '_out_16rl_custom2/030_038683.png', '_out_16rl_custom2/030_038685.png', '_out_16rl_custom2/030_038686.png', '_out_16rl_custom2/030_038687.png', '_out_16rl_custom2/030_038688.png', '_out_16rl_custom2/030_038689.png', '_out_16rl_custom2/030_038690.png', '_out_16rl_custom2/030_038691.png', '_out_16rl_custom2/030_038692.png', '_out_16rl_custom2/030_038693.png', '_out_16rl_custom2/030_038694.png', '_out_16rl_custom2/030_038695.png', '_out_16rl_custom2/030_038696.png', '_out_16rl_custom2/030_038697.png', '_out_16rl_custom2/030_038698.png', '_out_16rl_custom2/030_038700.png', '_out_16rl_custom2/030_038701.png', '_out_16rl_custom2/030_038702.png', '_out_16rl_custom2/030_038704.png', '_out_16rl_custom2/030_038705.png', '_out_16rl_custom2/030_038706.png', '_out_16rl_custom2/030_038707.png', '_out_16rl_custom2/030_038708.png', '_out_16rl_custom2/030_038709.png', '_out_16rl_custom2/030_038710.png', '_out_16rl_custom2/030_038711.png', '_out_16rl_custom2/030_038712.png', '_out_16rl_custom2/030_038713.png', '_out_16rl_custom2/030_038715.png', '_out_16rl_custom2/030_038717.png', '_out_16rl_custom2/030_038718.png', '_out_16rl_custom2/030_038720.png', '_out_16rl_custom2/030_038721.png', '_out_16rl_custom2/030_038722.png', '_out_16rl_custom2/030_038723.png', '_out_16rl_custom2/030_038724.png', '_out_16rl_custom2/030_038725.png', '_out_16rl_custom2/030_038726.png', '_out_16rl_custom2/030_038727.png', '_out_16rl_custom2/030_038728.png', '_out_16rl_custom2/030_038729.png', '_out_16rl_custom2/030_038731.png', '_out_16rl_custom2/030_038732.png', '_out_16rl_custom2/030_038734.png', '_out_16rl_custom2/030_038735.png', '_out_16rl_custom2/030_038736.png', '_out_16rl_custom2/030_038737.png', '_out_16rl_custom2/030_038738.png', '_out_16rl_custom2/030_038740.png', '_out_16rl_custom2/030_038741.png', '_out_16rl_custom2/030_038742.png', '_out_16rl_custom2/030_038743.png', '_out_16rl_custom2/030_038744.png', '_out_16rl_custom2/030_038745.png', '_out_16rl_custom2/030_038746.png', '_out_16rl_custom2/030_038747.png', '_out_16rl_custom2/030_038748.png', '_out_16rl_custom2/030_038749.png', '_out_16rl_custom2/030_038750.png', '_out_16rl_custom2/030_038751.png', '_out_16rl_custom2/030_038753.png', '_out_16rl_custom2/030_038754.png', '_out_16rl_custom2/030_038755.png', '_out_16rl_custom2/030_038756.png', '_out_16rl_custom2/030_038757.png', '_out_16rl_custom2/030_038759.png', '_out_16rl_custom2/030_038760.png', '_out_16rl_custom2/030_038761.png', '_out_16rl_custom2/030_038762.png', '_out_16rl_custom2/030_038764.png', '_out_16rl_custom2/030_038765.png', '_out_16rl_custom2/030_038766.png', '_out_16rl_custom2/030_038768.png', '_out_16rl_custom2/030_038769.png', '_out_16rl_custom2/030_038770.png', '_out_16rl_custom2/030_038771.png', '_out_16rl_custom2/030_038772.png', '_out_16rl_custom2/030_038773.png', '_out_16rl_custom2/030_038774.png', '_out_16rl_custom2/030_038775.png', '_out_16rl_custom2/030_038776.png', '_out_16rl_custom2/030_038777.png', '_out_16rl_custom2/030_038778.png', '_out_16rl_custom2/030_038780.png', '_out_16rl_custom2/030_038781.png', '_out_16rl_custom2/030_038782.png', '_out_16rl_custom2/030_038783.png', '_out_16rl_custom2/030_038784.png', '_out_16rl_custom2/030_038785.png', '_out_16rl_custom2/030_038786.png', '_out_16rl_custom2/030_038787.png', '_out_16rl_custom2/030_038788.png', '_out_16rl_custom2/030_038789.png', '_out_16rl_custom2/030_038790.png', '_out_16rl_custom2/030_038791.png', '_out_16rl_custom2/030_038792.png', '_out_16rl_custom2/030_038793.png', '_out_16rl_custom2/030_038794.png', '_out_16rl_custom2/030_038795.png', '_out_16rl_custom2/030_038796.png', '_out_16rl_custom2/030_038797.png', '_out_16rl_custom2/030_038799.png', '_out_16rl_custom2/030_038800.png', '_out_16rl_custom2/030_038801.png', '_out_16rl_custom2/030_038802.png', '_out_16rl_custom2/030_038804.png', '_out_16rl_custom2/030_038805.png', '_out_16rl_custom2/030_038807.png', '_out_16rl_custom2/030_038809.png', '_out_16rl_custom2/030_038810.png', '_out_16rl_custom2/030_038812.png', '_out_16rl_custom2/030_038813.png', '_out_16rl_custom2/030_038814.png', '_out_16rl_custom2/030_038815.png', '_out_16rl_custom2/030_038816.png', '_out_16rl_custom2/030_038817.png', '_out_16rl_custom2/030_038818.png', '_out_16rl_custom2/030_038819.png', '_out_16rl_custom2/030_038820.png', '_out_16rl_custom2/030_038822.png', '_out_16rl_custom2/030_038823.png', '_out_16rl_custom2/030_038824.png', '_out_16rl_custom2/030_038825.png', '_out_16rl_custom2/030_038827.png', '_out_16rl_custom2/030_038828.png', '_out_16rl_custom2/030_038830.png', '_out_16rl_custom2/030_038831.png', '_out_16rl_custom2/030_038832.png', '_out_16rl_custom2/030_038833.png', '_out_16rl_custom2/030_038835.png', '_out_16rl_custom2/030_038836.png', '_out_16rl_custom2/030_038837.png', '_out_16rl_custom2/030_038838.png', '_out_16rl_custom2/030_038839.png', '_out_16rl_custom2/030_038840.png', '_out_16rl_custom2/030_038841.png', '_out_16rl_custom2/030_038842.png', '_out_16rl_custom2/030_038843.png', '_out_16rl_custom2/030_038844.png', '_out_16rl_custom2/030_038845.png', '_out_16rl_custom2/030_038846.png', '_out_16rl_custom2/030_038847.png', '_out_16rl_custom2/030_038848.png', '_out_16rl_custom2/030_038849.png', '_out_16rl_custom2/030_038850.png', '_out_16rl_custom2/030_038851.png', '_out_16rl_custom2/030_038853.png', '_out_16rl_custom2/030_038854.png', '_out_16rl_custom2/030_038855.png', '_out_16rl_custom2/030_038856.png', '_out_16rl_custom2/030_038857.png', '_out_16rl_custom2/030_038858.png', '_out_16rl_custom2/030_038859.png', '_out_16rl_custom2/030_038860.png', '_out_16rl_custom2/030_038861.png', '_out_16rl_custom2/030_038862.png', '_out_16rl_custom2/030_038863.png', '_out_16rl_custom2/030_038864.png', '_out_16rl_custom2/030_038866.png', '_out_16rl_custom2/030_038868.png', '_out_16rl_custom2/030_038869.png', '_out_16rl_custom2/030_038870.png', '_out_16rl_custom2/030_038871.png', '_out_16rl_custom2/030_038872.png', '_out_16rl_custom2/030_038873.png', '_out_16rl_custom2/030_038874.png', '_out_16rl_custom2/030_038876.png', '_out_16rl_custom2/030_038877.png', '_out_16rl_custom2/030_038878.png', '_out_16rl_custom2/030_038879.png', '_out_16rl_custom2/030_038880.png', '_out_16rl_custom2/030_038882.png', '_out_16rl_custom2/030_038883.png', '_out_16rl_custom2/030_038884.png', '_out_16rl_custom2/030_038885.png', '_out_16rl_custom2/030_038887.png', '_out_16rl_custom2/030_038888.png', '_out_16rl_custom2/030_038889.png', '_out_16rl_custom2/030_038890.png', '_out_16rl_custom2/030_038892.png', '_out_16rl_custom2/030_038893.png', '_out_16rl_custom2/030_038894.png', '_out_16rl_custom2/030_038895.png', '_out_16rl_custom2/030_038896.png', '_out_16rl_custom2/030_038897.png', '_out_16rl_custom2/030_038898.png', '_out_16rl_custom2/030_038900.png', '_out_16rl_custom2/030_038901.png', '_out_16rl_custom2/030_038902.png', '_out_16rl_custom2/030_038903.png', '_out_16rl_custom2/030_038904.png', '_out_16rl_custom2/030_038905.png', '_out_16rl_custom2/030_038906.png', '_out_16rl_custom2/030_038907.png', '_out_16rl_custom2/030_038909.png', '_out_16rl_custom2/030_038910.png', '_out_16rl_custom2/030_038911.png', '_out_16rl_custom2/030_038913.png', '_out_16rl_custom2/030_038914.png', '_out_16rl_custom2/030_038915.png', '_out_16rl_custom2/030_038917.png', '_out_16rl_custom2/030_038918.png', '_out_16rl_custom2/030_038919.png', '_out_16rl_custom2/030_038920.png', '_out_16rl_custom2/030_038921.png', '_out_16rl_custom2/030_038922.png', '_out_16rl_custom2/030_038924.png', '_out_16rl_custom2/030_038925.png', '_out_16rl_custom2/030_038926.png', '_out_16rl_custom2/030_038927.png', '_out_16rl_custom2/030_038928.png', '_out_16rl_custom2/030_038929.png', '_out_16rl_custom2/030_038930.png', '_out_16rl_custom2/030_038931.png', '_out_16rl_custom2/030_038932.png', '_out_16rl_custom2/030_038934.png', '_out_16rl_custom2/030_038935.png', '_out_16rl_custom2/030_038936.png', '_out_16rl_custom2/030_038937.png', '_out_16rl_custom2/030_038938.png', '_out_16rl_custom2/030_038939.png', '_out_16rl_custom2/030_038940.png', '_out_16rl_custom2/030_038942.png', '_out_16rl_custom2/030_038943.png', '_out_16rl_custom2/030_038944.png', '_out_16rl_custom2/030_038946.png', '_out_16rl_custom2/030_038947.png', '_out_16rl_custom2/030_038948.png', '_out_16rl_custom2/030_038949.png', '_out_16rl_custom2/030_038950.png', '_out_16rl_custom2/030_038952.png', '_out_16rl_custom2/030_038953.png', '_out_16rl_custom2/030_038954.png', '_out_16rl_custom2/030_038955.png', '_out_16rl_custom2/030_038956.png', '_out_16rl_custom2/030_038957.png', '_out_16rl_custom2/030_038958.png', '_out_16rl_custom2/030_038959.png', '_out_16rl_custom2/030_038960.png', '_out_16rl_custom2/030_038961.png', '_out_16rl_custom2/030_038962.png', '_out_16rl_custom2/030_038963.png', '_out_16rl_custom2/030_038964.png', '_out_16rl_custom2/030_038965.png', '_out_16rl_custom2/030_038966.png', '_out_16rl_custom2/030_038967.png', '_out_16rl_custom2/030_038968.png', '_out_16rl_custom2/030_038969.png', '_out_16rl_custom2/030_038970.png', '_out_16rl_custom2/030_038971.png', '_out_16rl_custom2/030_038973.png', '_out_16rl_custom2/030_038974.png', '_out_16rl_custom2/030_038975.png', '_out_16rl_custom2/030_038976.png', '_out_16rl_custom2/030_038978.png', '_out_16rl_custom2/030_038979.png', '_out_16rl_custom2/030_038980.png', '_out_16rl_custom2/030_038982.png', '_out_16rl_custom2/030_038983.png', '_out_16rl_custom2/030_038984.png', '_out_16rl_custom2/030_038985.png', '_out_16rl_custom2/030_038986.png', '_out_16rl_custom2/030_038988.png', '_out_16rl_custom2/030_038989.png', '_out_16rl_custom2/030_038990.png', '_out_16rl_custom2/030_038991.png', '_out_16rl_custom2/030_038992.png', '_out_16rl_custom2/030_038993.png', '_out_16rl_custom2/030_038994.png', '_out_16rl_custom2/030_038996.png', '_out_16rl_custom2/030_038998.png', '_out_16rl_custom2/030_038999.png', '_out_16rl_custom2/030_039000.png', '_out_16rl_custom2/030_039001.png', '_out_16rl_custom2/030_039002.png', '_out_16rl_custom2/030_039003.png', '_out_16rl_custom2/030_039004.png', '_out_16rl_custom2/030_039005.png', '_out_16rl_custom2/030_039006.png', '_out_16rl_custom2/030_039007.png', '_out_16rl_custom2/030_039009.png', '_out_16rl_custom2/030_039010.png', '_out_16rl_custom2/030_039011.png', '_out_16rl_custom2/030_039013.png', '_out_16rl_custom2/030_039014.png', '_out_16rl_custom2/030_039015.png', '_out_16rl_custom2/030_039016.png', '_out_16rl_custom2/030_039017.png', '_out_16rl_custom2/030_039018.png', '_out_16rl_custom2/030_039020.png', '_out_16rl_custom2/030_039021.png', '_out_16rl_custom2/030_039022.png', '_out_16rl_custom2/030_039023.png', '_out_16rl_custom2/030_039024.png', '_out_16rl_custom2/030_039026.png', '_out_16rl_custom2/030_039027.png', '_out_16rl_custom2/030_039028.png', '_out_16rl_custom2/030_039029.png', '_out_16rl_custom2/030_039031.png', '_out_16rl_custom2/030_039032.png', '_out_16rl_custom2/030_039033.png', '_out_16rl_custom2/030_039034.png', '_out_16rl_custom2/030_039035.png', '_out_16rl_custom2/030_039037.png', '_out_16rl_custom2/030_039038.png', '_out_16rl_custom2/030_039039.png', '_out_16rl_custom2/030_039040.png', '_out_16rl_custom2/030_039042.png', '_out_16rl_custom2/030_039043.png', '_out_16rl_custom2/030_039044.png', '_out_16rl_custom2/030_039045.png', '_out_16rl_custom2/030_039047.png', '_out_16rl_custom2/030_039048.png', '_out_16rl_custom2/030_039049.png', '_out_16rl_custom2/030_039050.png', '_out_16rl_custom2/030_039052.png', '_out_16rl_custom2/030_039053.png', '_out_16rl_custom2/030_039054.png', '_out_16rl_custom2/030_039055.png', '_out_16rl_custom2/030_039056.png', '_out_16rl_custom2/030_039057.png', '_out_16rl_custom2/030_039058.png', '_out_16rl_custom2/030_039059.png', '_out_16rl_custom2/030_039060.png', '_out_16rl_custom2/030_039062.png', '_out_16rl_custom2/030_039064.png', '_out_16rl_custom2/030_039065.png', '_out_16rl_custom2/030_039067.png', '_out_16rl_custom2/030_039068.png', '_out_16rl_custom2/030_039069.png', '_out_16rl_custom2/030_039071.png', '_out_16rl_custom2/030_039072.png', '_out_16rl_custom2/030_039073.png', '_out_16rl_custom2/030_039075.png', '_out_16rl_custom2/030_039077.png', '_out_16rl_custom2/030_039078.png', '_out_16rl_custom2/030_039080.png', '_out_16rl_custom2/030_039082.png', '_out_16rl_custom2/030_039083.png', '_out_16rl_custom2/030_039085.png', '_out_16rl_custom2/030_039086.png', '_out_16rl_custom2/030_039087.png', '_out_16rl_custom2/030_039088.png', '_out_16rl_custom2/030_039089.png', '_out_16rl_custom2/030_039090.png', '_out_16rl_custom2/030_039092.png', '_out_16rl_custom2/030_039093.png', '_out_16rl_custom2/030_039094.png', '_out_16rl_custom2/030_039095.png', '_out_16rl_custom2/030_039096.png', '_out_16rl_custom2/030_039097.png', '_out_16rl_custom2/030_039098.png', '_out_16rl_custom2/030_039099.png', '_out_16rl_custom2/030_039100.png', '_out_16rl_custom2/030_039101.png', '_out_16rl_custom2/030_039102.png', '_out_16rl_custom2/030_039103.png', '_out_16rl_custom2/030_039104.png', '_out_16rl_custom2/030_039106.png', '_out_16rl_custom2/030_039108.png', '_out_16rl_custom2/030_039109.png', '_out_16rl_custom2/030_039110.png', '_out_16rl_custom2/030_039111.png', '_out_16rl_custom2/030_039112.png', '_out_16rl_custom2/030_039113.png', '_out_16rl_custom2/030_039114.png', '_out_16rl_custom2/030_039115.png', '_out_16rl_custom2/030_039116.png', '_out_16rl_custom2/030_039117.png', '_out_16rl_custom2/030_039118.png', '_out_16rl_custom2/030_039119.png', '_out_16rl_custom2/030_039120.png', '_out_16rl_custom2/030_039121.png', '_out_16rl_custom2/030_039122.png', '_out_16rl_custom2/030_039123.png', '_out_16rl_custom2/030_039124.png', '_out_16rl_custom2/030_039126.png', '_out_16rl_custom2/030_039127.png', '_out_16rl_custom2/030_039128.png', '_out_16rl_custom2/030_039130.png']
WARNING: Version mismatch detected: You are trying to connect to a simulator that might be incompatible with this API 
WARNING: Client API version     = 0.9.15 
WARNING: Simulator API version  = 0.9.14 
2023-12-30 05:18:02.407186: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904
2023-12-30 05:18:03.320499: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f1f8f483460 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-12-30 05:18:03.320515: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 SUPER, Compute Capability 7.5
2023-12-30 05:18:03.323311: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1703931483.393600 1549988 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
  0%|          | 0/971 [00:00<?, ?episode/s]
Started episode 30 of 1000
2023-12-30 05:19:02.088770: W external/local_tsl/tsl/framework/bfc_allocator.cc:366] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.
Finished episode 30 of 1000
Saved model from episode 30. Count of epochs trained: 21176
  0%|          | 1/971 [03:33<57:24:29, 213.06s/episode]
Started episode 31 of 1000
Finished episode 31 of 1000
Saved model from episode 31. Count of epochs trained: 21477
  0%|          | 2/971 [07:04<57:06:55, 212.19s/episode]
Started episode 32 of 1000
Finished episode 32 of 1000
Saved model from episode 32. Count of epochs trained: 21737
  0%|          | 3/971 [10:10<53:45:45, 199.94s/episode]
Started episode 33 of 1000
Finished episode 33 of 1000
Saved model from episode 33. Count of epochs trained: 21930
  0%|          | 4/971 [12:28<47:09:50, 175.58s/episode]
Started episode 34 of 1000
Finished episode 34 of 1000
Saved model from episode 34. Count of epochs trained: 22059
  1%|          | 5/971 [14:01<39:06:18, 145.73s/episode]
Started episode 35 of 1000
Finished episode 35 of 1000
Saved model from episode 35. Count of epochs trained: 22070
  1%|          | 6/971 [14:09<26:35:25, 99.20s/episode] 
Started episode 36 of 1000
Finished episode 36 of 1000
Saved model from episode 36. Count of epochs trained: 22145
  1%|          | 7/971 [15:05<22:42:46, 84.82s/episode]
Started episode 37 of 1000
Finished episode 37 of 1000
Saved model from episode 37. Count of epochs trained: 22153
  1%|          | 8/971 [15:11<15:58:29, 59.72s/episode]
Started episode 38 of 1000
Finished episode 38 of 1000
Saved model from episode 38. Count of epochs trained: 22159
  1%|          | 9/971 [15:16<11:23:54, 42.66s/episode]
Started episode 39 of 1000
Finished episode 39 of 1000
Saved model from episode 39. Count of epochs trained: 22205
  1%|1         | 10/971 [15:49<10:39:08, 39.90s/episode]
Started episode 40 of 1000
Finished episode 40 of 1000
Saved model from episode 40. Count of epochs trained: 22212
  1%|1         | 11/971 [15:56<7:56:44, 29.80s/episode] 
Started episode 41 of 1000
Finished episode 41 of 1000
Saved model from episode 41. Count of epochs trained: 22256
  1%|1         | 12/971 [16:29<8:08:52, 30.59s/episode]
Started episode 42 of 1000
Finished episode 42 of 1000
Saved model from episode 42. Count of epochs trained: 22260
  1%|1         | 13/971 [16:33<5:59:33, 22.52s/episode]
Started episode 43 of 1000
Finished episode 43 of 1000
Saved model from episode 43. Count of epochs trained: 22265
  1%|1         | 14/971 [16:37<4:30:09, 16.94s/episode]
Started episode 44 of 1000
Finished episode 44 of 1000
Saved model from episode 44. Count of epochs trained: 22270
  2%|1         | 15/971 [16:41<3:30:26, 13.21s/episode]
Started episode 45 of 1000
Finished episode 45 of 1000
Saved model from episode 45. Count of epochs trained: 22277
  2%|1         | 16/971 [16:46<2:51:33, 10.78s/episode]
Started episode 46 of 1000
Finished episode 46 of 1000
Saved model from episode 46. Count of epochs trained: 22291
  2%|1         | 17/971 [16:57<2:51:38, 10.79s/episode]
Started episode 47 of 1000
Finished episode 47 of 1000
Saved model from episode 47. Count of epochs trained: 22296
  2%|1         | 18/971 [17:02<2:20:55,  8.87s/episode]
Started episode 48 of 1000
Finished episode 48 of 1000
Saved model from episode 48. Count of epochs trained: 22301
  2%|1         | 19/971 [17:06<1:58:19,  7.46s/episode]
Started episode 49 of 1000
Finished episode 49 of 1000
Saved model from episode 49. Count of epochs trained: 22305
  2%|2         | 20/971 [17:10<1:40:06,  6.32s/episode]
Started episode 50 of 1000
Exception in thread Thread-1:
Traceback (most recent call last):
  File "/home/nsambhu/anaconda3/envs/carla_py3.9/lib/python3.9/threading.py", line 980, in _bootstrap_inner
    self.run()
  File "/home/nsambhu/anaconda3/envs/carla_py3.9/lib/python3.9/threading.py", line 917, in run
    self._target(*self._args, **self._kwargs)
  File "/home/nsambhu/github/carla-race/run/2023_12_18_16rl_custom2.py", line 459, in train_in_loop
    self.train()
  File "/home/nsambhu/github/carla-race/run/2023_12_18_16rl_custom2.py", line 379, in train
    current_qs_list = self.model.predict(current_states, PREDICTION_BATCH_SIZE, verbose=0)
  File "/home/nsambhu/anaconda3/envs/carla_py3.9/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/nsambhu/anaconda3/envs/carla_py3.9/lib/python3.9/site-packages/keras/src/engine/training.py", line 2655, in predict
    tmp_batch_outputs = self.predict_function(iterator)
TypeError: 'NoneType' object is not callable
Finished episode 50 of 1000
Saved model from episode 50. Count of epochs trained: 22309
  2%|2         | 21/971 [17:14<1:30:48,  5.73s/episode]
Started episode 51 of 1000
Finished episode 51 of 1000
Saved model from episode 51. Count of epochs trained: 22309
  2%|2         | 22/971 [17:18<1:21:10,  5.13s/episode]
Started episode 52 of 1000
Finished episode 52 of 1000
Saved model from episode 52. Count of epochs trained: 22309
  2%|2         | 23/971 [17:21<1:12:56,  4.62s/episode]
Started episode 53 of 1000
Finished episode 53 of 1000
Saved model from episode 53. Count of epochs trained: 22309
  2%|2         | 24/971 [17:25<1:07:36,  4.28s/episode]
Started episode 54 of 1000
Finished episode 54 of 1000
Saved model from episode 54. Count of epochs trained: 22309
  3%|2         | 25/971 [17:28<1:04:02,  4.06s/episode]
Started episode 55 of 1000
Finished episode 55 of 1000
Saved model from episode 55. Count of epochs trained: 22309
  3%|2         | 26/971 [17:35<1:17:34,  4.93s/episode]
Started episode 56 of 1000
Finished episode 56 of 1000
Saved model from episode 56. Count of epochs trained: 22309
  3%|2         | 27/971 [17:39<1:11:18,  4.53s/episode]
Started episode 57 of 1000
Finished episode 57 of 1000
Saved model from episode 57. Count of epochs trained: 22309
  3%|2         | 28/971 [17:43<1:08:45,  4.38s/episode]
Started episode 58 of 1000
Finished episode 58 of 1000
Saved model from episode 58. Count of epochs trained: 22309
  3%|2         | 29/971 [17:47<1:08:10,  4.34s/episode]
Started episode 59 of 1000
Finished episode 59 of 1000
Saved model from episode 59. Count of epochs trained: 22309
  3%|3         | 30/971 [17:50<1:02:42,  4.00s/episode]
Started episode 60 of 1000
Finished episode 60 of 1000
Saved model from episode 60. Count of epochs trained: 22309
  3%|3         | 31/971 [17:55<1:06:17,  4.23s/episode]
Started episode 61 of 1000
Finished episode 61 of 1000
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
Count of epochs trained: 22309	Goal: 23086
2023-12-30 13:44:23.600696: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-12-30 13:44:23.622812: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2023-12-30 13:44:23.622829: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2023-12-30 13:44:23.623371: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2023-12-30 13:44:23.626761: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-12-30 13:44:24.042479: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-12-30 13:44:24.353910: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-12-30 13:44:24.387275: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-12-30 13:44:24.387478: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-12-30 13:44:24.390555: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-12-30 13:44:24.390826: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-12-30 13:44:24.391049: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-12-30 13:44:25.350300: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-12-30 13:44:25.350449: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-12-30 13:44:25.350590: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-12-30 13:44:25.350717: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4407 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 SUPER, pci bus id: 0000:02:00.0, compute capability: 7.5
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d_input (InputLayer)   [(None, 128, 128, 3)]     0         
                                                                 
 conv2d (Conv2D)             (None, 128, 128, 64)      1792      
                                                                 
 max_pooling2d (MaxPooling2  (None, 64, 64, 64)        0         
 D)                                                              
                                                                 
 batch_normalization (Batch  (None, 64, 64, 64)        256       
 Normalization)                                                  
                                                                 
 activation (Activation)     (None, 64, 64, 64)        0         
                                                                 
 conv2d_1 (Conv2D)           (None, 64, 64, 64)        36928     
                                                                 
 max_pooling2d_1 (MaxPoolin  (None, 32, 32, 64)        0         
 g2D)                                                            
                                                                 
 batch_normalization_1 (Bat  (None, 32, 32, 64)        256       
 chNormalization)                                                
                                                                 
 activation_1 (Activation)   (None, 32, 32, 64)        0         
                                                                 
 conv2d_2 (Conv2D)           (None, 32, 32, 64)        36928     
                                                                 
 max_pooling2d_2 (MaxPoolin  (None, 16, 16, 64)        0         
 g2D)                                                            
                                                                 
 batch_normalization_2 (Bat  (None, 16, 16, 64)        256       
 chNormalization)                                                
                                                                 
 activation_2 (Activation)   (None, 16, 16, 64)        0         
                                                                 
 conv2d_3 (Conv2D)           (None, 16, 16, 64)        36928     
                                                                 
 max_pooling2d_3 (MaxPoolin  (None, 8, 8, 64)          0         
 g2D)                                                            
                                                                 
 batch_normalization_3 (Bat  (None, 8, 8, 64)          256       
 chNormalization)                                                
                                                                 
 activation_3 (Activation)   (None, 8, 8, 64)          0         
                                                                 
 flatten (Flatten)           (None, 4096)              0         
                                                                 
 dense (Dense)               (None, 2541)              10410477  
                                                                 
=================================================================
Total params: 10524077 (40.15 MB)
Trainable params: 10523565 (40.14 MB)
Non-trainable params: 512 (2.00 KB)
_________________________________________________________________
None
Model: "model_1"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d_4_input (InputLayer  [(None, 128, 128, 3)]     0         
 )                                                               
                                                                 
 conv2d_4 (Conv2D)           (None, 128, 128, 64)      1792      
                                                                 
 max_pooling2d_4 (MaxPoolin  (None, 64, 64, 64)        0         
 g2D)                                                            
                                                                 
 batch_normalization_4 (Bat  (None, 64, 64, 64)        256       
 chNormalization)                                                
                                                                 
 activation_4 (Activation)   (None, 64, 64, 64)        0         
                                                                 
 conv2d_5 (Conv2D)           (None, 64, 64, 64)        36928     
                                                                 
 max_pooling2d_5 (MaxPoolin  (None, 32, 32, 64)        0         
 g2D)                                                            
                                                                 
 batch_normalization_5 (Bat  (None, 32, 32, 64)        256       
 chNormalization)                                                
                                                                 
 activation_5 (Activation)   (None, 32, 32, 64)        0         
                                                                 
 conv2d_6 (Conv2D)           (None, 32, 32, 64)        36928     
                                                                 
 max_pooling2d_6 (MaxPoolin  (None, 16, 16, 64)        0         
 g2D)                                                            
                                                                 
 batch_normalization_6 (Bat  (None, 16, 16, 64)        256       
 chNormalization)                                                
                                                                 
 activation_6 (Activation)   (None, 16, 16, 64)        0         
                                                                 
 conv2d_7 (Conv2D)           (None, 16, 16, 64)        36928     
                                                                 
 max_pooling2d_7 (MaxPoolin  (None, 8, 8, 64)          0         
 g2D)                                                            
                                                                 
 batch_normalization_7 (Bat  (None, 8, 8, 64)          256       
 chNormalization)                                                
                                                                 
 activation_7 (Activation)   (None, 8, 8, 64)          0         
                                                                 
 flatten_1 (Flatten)         (None, 4096)              0         
                                                                 
 dense_1 (Dense)             (None, 2541)              10410477  
                                                                 
=================================================================
Total params: 10524077 (40.15 MB)
Trainable params: 10523565 (40.14 MB)
Non-trainable params: 512 (2.00 KB)
_________________________________________________________________
None
Model: "model_2"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d_8_input (InputLayer  [(None, 128, 128, 3)]     0         
 )                                                               
                                                                 
 conv2d_8 (Conv2D)           (None, 128, 128, 64)      1792      
                                                                 
 max_pooling2d_8 (MaxPoolin  (None, 64, 64, 64)        0         
 g2D)                                                            
                                                                 
 batch_normalization_8 (Bat  (None, 64, 64, 64)        256       
 chNormalization)                                                
                                                                 
 activation_8 (Activation)   (None, 64, 64, 64)        0         
                                                                 
 conv2d_9 (Conv2D)           (None, 64, 64, 64)        36928     
                                                                 
 max_pooling2d_9 (MaxPoolin  (None, 32, 32, 64)        0         
 g2D)                                                            
                                                                 
 batch_normalization_9 (Bat  (None, 32, 32, 64)        256       
 chNormalization)                                                
                                                                 
 activation_9 (Activation)   (None, 32, 32, 64)        0         
                                                                 
 conv2d_10 (Conv2D)          (None, 32, 32, 64)        36928     
                                                                 
 max_pooling2d_10 (MaxPooli  (None, 16, 16, 64)        0         
 ng2D)                                                           
                                                                 
 batch_normalization_10 (Ba  (None, 16, 16, 64)        256       
 tchNormalization)                                               
                                                                 
 activation_10 (Activation)  (None, 16, 16, 64)        0         
                                                                 
 conv2d_11 (Conv2D)          (None, 16, 16, 64)        36928     
                                                                 
 max_pooling2d_11 (MaxPooli  (None, 8, 8, 64)          0         
 ng2D)                                                           
                                                                 
 batch_normalization_11 (Ba  (None, 8, 8, 64)          256       
 tchNormalization)                                               
                                                                 
 activation_11 (Activation)  (None, 8, 8, 64)          0         
                                                                 
 flatten_2 (Flatten)         (None, 4096)              0         
                                                                 
 dense_2 (Dense)             (None, 2541)              10410477  
                                                                 
=================================================================
Total params: 10524077 (40.15 MB)
Trainable params: 10523565 (40.14 MB)
Non-trainable params: 512 (2.00 KB)
_________________________________________________________________
None
Models in tmp ['tmp/029.20956.model', 'tmp/030.21176.model', 'tmp/031.21476.model', 'tmp/032.21737.model', 'tmp/033.21930.model', 'tmp/034.22058.model', 'tmp/035.22070.model', 'tmp/036.22145.model', 'tmp/037.22152.model', 'tmp/038.22159.model', 'tmp/039.22204.model', 'tmp/040.22212.model', 'tmp/041.22255.model', 'tmp/042.22260.model', 'tmp/043.22264.model', 'tmp/044.22270.model', 'tmp/045.22276.model', 'tmp/046.22290.model', 'tmp/047.22295.model', 'tmp/048.22300.model', 'tmp/049.22305.model', 'tmp/050.22309.model', 'tmp/051.22309.model', 'tmp/052.22309.model', 'tmp/053.22309.model', 'tmp/054.22309.model', 'tmp/055.22309.model', 'tmp/056.22309.model', 'tmp/057.22309.model', 'tmp/058.22309.model', 'tmp/059.22309.model', 'tmp/060.22309.model']
Load model tmp/060.22309.model
Leftover images from failed episode: ['_out_16rl_custom2/061_016005.png', '_out_16rl_custom2/061_016007.png', '_out_16rl_custom2/061_016008.png', '_out_16rl_custom2/061_016010.png', '_out_16rl_custom2/061_016011.png', '_out_16rl_custom2/061_016012.png', '_out_16rl_custom2/061_016014.png', '_out_16rl_custom2/061_016015.png', '_out_16rl_custom2/061_016016.png', '_out_16rl_custom2/061_016017.png', '_out_16rl_custom2/061_016019.png', '_out_16rl_custom2/061_016021.png', '_out_16rl_custom2/061_016022.png', '_out_16rl_custom2/061_016023.png', '_out_16rl_custom2/061_016024.png', '_out_16rl_custom2/061_016025.png', '_out_16rl_custom2/061_016027.png', '_out_16rl_custom2/061_016028.png', '_out_16rl_custom2/061_016030.png', '_out_16rl_custom2/061_016031.png', '_out_16rl_custom2/061_016032.png', '_out_16rl_custom2/061_016034.png', '_out_16rl_custom2/061_016036.png', '_out_16rl_custom2/061_016038.png', '_out_16rl_custom2/061_016039.png', '_out_16rl_custom2/061_016040.png', '_out_16rl_custom2/061_016041.png', '_out_16rl_custom2/061_016042.png', '_out_16rl_custom2/061_016043.png', '_out_16rl_custom2/061_016044.png', '_out_16rl_custom2/061_016045.png', '_out_16rl_custom2/061_016046.png', '_out_16rl_custom2/061_016047.png', '_out_16rl_custom2/061_016048.png']
WARNING: Version mismatch detected: You are trying to connect to a simulator that might be incompatible with this API 
WARNING: Client API version     = 0.9.15 
WARNING: Simulator API version  = 0.9.14 
2023-12-30 13:44:39.141829: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904
2023-12-30 13:44:40.097486: I external/local_xla/xla/service/service.cc:168] XLA service 0x7fe3141dc300 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-12-30 13:44:40.097501: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 SUPER, Compute Capability 7.5
2023-12-30 13:44:40.100325: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1703961880.176129 1681744 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
  0%|          | 0/940 [00:00<?, ?episode/s]
Started episode 61 of 1000
Finished episode 61 of 1000
Saved model from episode 61. Count of epochs trained: 22548
  0%|          | 1/940 [02:37<41:06:59, 157.63s/episode]
Started episode 62 of 1000
Finished episode 62 of 1000
Saved model from episode 62. Count of epochs trained: 22848
  0%|          | 2/940 [05:14<40:56:00, 157.10s/episode]
Started episode 63 of 1000
Finished episode 63 of 1000
Saved model from episode 63. Count of epochs trained: 23105
  0%|          | 3/940 [07:28<38:07:16, 146.46s/episode]
Started episode 64 of 1000
Finished episode 64 of 1000
Saved model from episode 64. Count of epochs trained: 23383
  0%|          | 4/940 [09:51<37:44:36, 145.17s/episode]
Started episode 65 of 1000
Finished episode 65 of 1000
Saved model from episode 65. Count of epochs trained: 23560
  1%|          | 5/940 [11:23<32:45:37, 126.14s/episode]
Started episode 66 of 1000
Finished episode 66 of 1000
Saved model from episode 66. Count of epochs trained: 23575
  1%|          | 6/940 [11:32<22:20:06, 86.09s/episode] 
Started episode 67 of 1000
Finished episode 67 of 1000
Saved model from episode 67. Count of epochs trained: 23638
  1%|          | 7/940 [12:05<17:52:07, 68.95s/episode]
Started episode 68 of 1000
Finished episode 68 of 1000
Saved model from episode 68. Count of epochs trained: 23647
  1%|          | 8/940 [12:11<12:36:45, 48.72s/episode]
Started episode 69 of 1000
Finished episode 69 of 1000
Saved model from episode 69. Count of epochs trained: 23656
  1%|          | 9/940 [12:16<9:04:12, 35.07s/episode] 
Started episode 70 of 1000
Finished episode 70 of 1000
Saved model from episode 70. Count of epochs trained: 23697
  1%|1         | 10/940 [12:39<8:07:19, 31.44s/episode]
Started episode 71 of 1000
Finished episode 71 of 1000
Saved model from episode 71. Count of epochs trained: 23703
  1%|1         | 11/940 [12:43<5:55:44, 22.98s/episode]
Started episode 72 of 1000
Finished episode 72 of 1000
Saved model from episode 72. Count of epochs trained: 23709
  1%|1         | 12/940 [12:46<4:24:25, 17.10s/episode]
Started episode 73 of 1000
Finished episode 73 of 1000
Saved model from episode 73. Count of epochs trained: 23742
  1%|1         | 13/940 [13:05<4:31:11, 17.55s/episode]
Started episode 74 of 1000
Finished episode 74 of 1000
Count of epochs trained: 23748	Goal: 24981
Count of epochs trained: 23872	Goal: 24981
Count of epochs trained: 23997	Goal: 24981
Count of epochs trained: 24121	Goal: 24981
Count of epochs trained: 24245	Goal: 24981
Count of epochs trained: 24369	Goal: 24981
Count of epochs trained: 24493	Goal: 24981
Count of epochs trained: 24617	Goal: 24981
Count of epochs trained: 24740	Goal: 24981
Count of epochs trained: 24864	Goal: 24981
Saved model from episode 74. Count of epochs trained: 24988
  1%|1         | 14/940 [23:10<50:08:28, 194.93s/episode]
Started episode 75 of 1000
Finished episode 75 of 1000
Count of epochs trained: 25010	Goal: 26227
Count of epochs trained: 25133	Goal: 26227
Count of epochs trained: 25257	Goal: 26227
Count of epochs trained: 25381	Goal: 26227
Count of epochs trained: 25505	Goal: 26227
Count of epochs trained: 25630	Goal: 26227
Count of epochs trained: 25754	Goal: 26227
Count of epochs trained: 25879	Goal: 26227
Count of epochs trained: 26004	Goal: 26227
Count of epochs trained: 26128	Goal: 26227
Saved model from episode 75. Count of epochs trained: 26253
  2%|1         | 15/940 [33:24<82:31:15, 321.16s/episode]
Started episode 76 of 1000
Finished episode 76 of 1000
Count of epochs trained: 26271	Goal: 27492
Count of epochs trained: 26396	Goal: 27492
Count of epochs trained: 26520	Goal: 27492
Count of epochs trained: 26644	Goal: 27492
Count of epochs trained: 26769	Goal: 27492
Count of epochs trained: 26893	Goal: 27492
Count of epochs trained: 27017	Goal: 27492
Count of epochs trained: 27142	Goal: 27492
Count of epochs trained: 27266	Goal: 27492
Count of epochs trained: 27390	Goal: 27492
Saved model from episode 76. Count of epochs trained: 27516
  2%|1         | 16/940 [43:35<104:52:12, 408.59s/episode]
Started episode 77 of 1000
Finished episode 77 of 1000
Count of epochs trained: 27521	Goal: 28755
Count of epochs trained: 27645	Goal: 28755
Count of epochs trained: 27769	Goal: 28755
Count of epochs trained: 27893	Goal: 28755
Count of epochs trained: 28016	Goal: 28755
Count of epochs trained: 28140	Goal: 28755
Count of epochs trained: 28264	Goal: 28755
Count of epochs trained: 28388	Goal: 28755
Count of epochs trained: 28511	Goal: 28755
Count of epochs trained: 28635	Goal: 28755
Saved model from episode 77. Count of epochs trained: 28760
  2%|1         | 17/940 [53:39<119:49:36, 467.36s/episode]
Started episode 78 of 1000
Finished episode 78 of 1000
Count of epochs trained: 28779	Goal: 29999
Count of epochs trained: 28903	Goal: 29999
Count of epochs trained: 29027	Goal: 29999
Count of epochs trained: 29151	Goal: 29999
Count of epochs trained: 29276	Goal: 29999
Count of epochs trained: 29400	Goal: 29999
Count of epochs trained: 29524	Goal: 29999
Count of epochs trained: 29648	Goal: 29999
Count of epochs trained: 29772	Goal: 29999
Count of epochs trained: 29896	Goal: 29999
Saved model from episode 78. Count of epochs trained: 30021
  2%|1         | 18/940 [1:03:51<130:49:13, 510.80s/episode]
Started episode 79 of 1000
Finished episode 79 of 1000
Count of epochs trained: 30291	Goal: 31260
Count of epochs trained: 30415	Goal: 31260
Count of epochs trained: 30540	Goal: 31260
Count of epochs trained: 30663	Goal: 31260
Count of epochs trained: 30787	Goal: 31260
Count of epochs trained: 30911	Goal: 31260
Count of epochs trained: 31035	Goal: 31260
Count of epochs trained: 31159	Goal: 31260
Saved model from episode 79. Count of epochs trained: 31283
  2%|2         | 19/940 [1:14:24<140:01:38, 547.34s/episode]
Started episode 80 of 1000
Exception in thread Thread-1:
Traceback (most recent call last):
  File "/home/nsambhu/anaconda3/envs/carla_py3.9/lib/python3.9/threading.py", line 980, in _bootstrap_inner
    self.run()
  File "/home/nsambhu/anaconda3/envs/carla_py3.9/lib/python3.9/threading.py", line 917, in run
    self._target(*self._args, **self._kwargs)
  File "/home/nsambhu/github/carla-race/run/2023_12_18_16rl_custom2.py", line 459, in train_in_loop
    self.train()
  File "/home/nsambhu/github/carla-race/run/2023_12_18_16rl_custom2.py", line 379, in train
    current_qs_list = self.model.predict(current_states, PREDICTION_BATCH_SIZE, verbose=0)
  File "/home/nsambhu/anaconda3/envs/carla_py3.9/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/nsambhu/anaconda3/envs/carla_py3.9/lib/python3.9/site-packages/keras/src/engine/training.py", line 2655, in predict
    tmp_batch_outputs = self.predict_function(iterator)
TypeError: 'NoneType' object is not callable
Finished episode 80 of 1000
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
Count of epochs trained: 31289	Goal: 32522
2023-12-30 16:50:24.564167: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-12-30 16:50:24.586771: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2023-12-30 16:50:24.586790: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2023-12-30 16:50:24.587367: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2023-12-30 16:50:24.590949: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-12-30 16:50:25.026270: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-12-30 16:50:25.371915: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-12-30 16:50:25.406758: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-12-30 16:50:25.407119: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-12-30 16:50:25.410463: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-12-30 16:50:25.410661: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-12-30 16:50:25.410861: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-12-30 16:50:26.255728: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-12-30 16:50:26.255873: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-12-30 16:50:26.255985: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-12-30 16:50:26.256107: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4406 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 SUPER, pci bus id: 0000:02:00.0, compute capability: 7.5
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d_input (InputLayer)   [(None, 128, 128, 3)]     0         
                                                                 
 conv2d (Conv2D)             (None, 128, 128, 64)      1792      
                                                                 
 max_pooling2d (MaxPooling2  (None, 64, 64, 64)        0         
 D)                                                              
                                                                 
 batch_normalization (Batch  (None, 64, 64, 64)        256       
 Normalization)                                                  
                                                                 
 activation (Activation)     (None, 64, 64, 64)        0         
                                                                 
 conv2d_1 (Conv2D)           (None, 64, 64, 64)        36928     
                                                                 
 max_pooling2d_1 (MaxPoolin  (None, 32, 32, 64)        0         
 g2D)                                                            
                                                                 
 batch_normalization_1 (Bat  (None, 32, 32, 64)        256       
 chNormalization)                                                
                                                                 
 activation_1 (Activation)   (None, 32, 32, 64)        0         
                                                                 
 conv2d_2 (Conv2D)           (None, 32, 32, 64)        36928     
                                                                 
 max_pooling2d_2 (MaxPoolin  (None, 16, 16, 64)        0         
 g2D)                                                            
                                                                 
 batch_normalization_2 (Bat  (None, 16, 16, 64)        256       
 chNormalization)                                                
                                                                 
 activation_2 (Activation)   (None, 16, 16, 64)        0         
                                                                 
 conv2d_3 (Conv2D)           (None, 16, 16, 64)        36928     
                                                                 
 max_pooling2d_3 (MaxPoolin  (None, 8, 8, 64)          0         
 g2D)                                                            
                                                                 
 batch_normalization_3 (Bat  (None, 8, 8, 64)          256       
 chNormalization)                                                
                                                                 
 activation_3 (Activation)   (None, 8, 8, 64)          0         
                                                                 
 flatten (Flatten)           (None, 4096)              0         
                                                                 
 dense (Dense)               (None, 2541)              10410477  
                                                                 
=================================================================
Total params: 10524077 (40.15 MB)
Trainable params: 10523565 (40.14 MB)
Non-trainable params: 512 (2.00 KB)
_________________________________________________________________
None
Model: "model_1"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d_4_input (InputLayer  [(None, 128, 128, 3)]     0         
 )                                                               
                                                                 
 conv2d_4 (Conv2D)           (None, 128, 128, 64)      1792      
                                                                 
 max_pooling2d_4 (MaxPoolin  (None, 64, 64, 64)        0         
 g2D)                                                            
                                                                 
 batch_normalization_4 (Bat  (None, 64, 64, 64)        256       
 chNormalization)                                                
                                                                 
 activation_4 (Activation)   (None, 64, 64, 64)        0         
                                                                 
 conv2d_5 (Conv2D)           (None, 64, 64, 64)        36928     
                                                                 
 max_pooling2d_5 (MaxPoolin  (None, 32, 32, 64)        0         
 g2D)                                                            
                                                                 
 batch_normalization_5 (Bat  (None, 32, 32, 64)        256       
 chNormalization)                                                
                                                                 
 activation_5 (Activation)   (None, 32, 32, 64)        0         
                                                                 
 conv2d_6 (Conv2D)           (None, 32, 32, 64)        36928     
                                                                 
 max_pooling2d_6 (MaxPoolin  (None, 16, 16, 64)        0         
 g2D)                                                            
                                                                 
 batch_normalization_6 (Bat  (None, 16, 16, 64)        256       
 chNormalization)                                                
                                                                 
 activation_6 (Activation)   (None, 16, 16, 64)        0         
                                                                 
 conv2d_7 (Conv2D)           (None, 16, 16, 64)        36928     
                                                                 
 max_pooling2d_7 (MaxPoolin  (None, 8, 8, 64)          0         
 g2D)                                                            
                                                                 
 batch_normalization_7 (Bat  (None, 8, 8, 64)          256       
 chNormalization)                                                
                                                                 
 activation_7 (Activation)   (None, 8, 8, 64)          0         
                                                                 
 flatten_1 (Flatten)         (None, 4096)              0         
                                                                 
 dense_1 (Dense)             (None, 2541)              10410477  
                                                                 
=================================================================
Total params: 10524077 (40.15 MB)
Trainable params: 10523565 (40.14 MB)
Non-trainable params: 512 (2.00 KB)
_________________________________________________________________
None
Model: "model_2"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d_8_input (InputLayer  [(None, 128, 128, 3)]     0         
 )                                                               
                                                                 
 conv2d_8 (Conv2D)           (None, 128, 128, 64)      1792      
                                                                 
 max_pooling2d_8 (MaxPoolin  (None, 64, 64, 64)        0         
 g2D)                                                            
                                                                 
 batch_normalization_8 (Bat  (None, 64, 64, 64)        256       
 chNormalization)                                                
                                                                 
 activation_8 (Activation)   (None, 64, 64, 64)        0         
                                                                 
 conv2d_9 (Conv2D)           (None, 64, 64, 64)        36928     
                                                                 
 max_pooling2d_9 (MaxPoolin  (None, 32, 32, 64)        0         
 g2D)                                                            
                                                                 
 batch_normalization_9 (Bat  (None, 32, 32, 64)        256       
 chNormalization)                                                
                                                                 
 activation_9 (Activation)   (None, 32, 32, 64)        0         
                                                                 
 conv2d_10 (Conv2D)          (None, 32, 32, 64)        36928     
                                                                 
 max_pooling2d_10 (MaxPooli  (None, 16, 16, 64)        0         
 ng2D)                                                           
                                                                 
 batch_normalization_10 (Ba  (None, 16, 16, 64)        256       
 tchNormalization)                                               
                                                                 
 activation_10 (Activation)  (None, 16, 16, 64)        0         
                                                                 
 conv2d_11 (Conv2D)          (None, 16, 16, 64)        36928     
                                                                 
 max_pooling2d_11 (MaxPooli  (None, 8, 8, 64)          0         
 ng2D)                                                           
                                                                 
 batch_normalization_11 (Ba  (None, 8, 8, 64)          256       
 tchNormalization)                                               
                                                                 
 activation_11 (Activation)  (None, 8, 8, 64)          0         
                                                                 
 flatten_2 (Flatten)         (None, 4096)              0         
                                                                 
 dense_2 (Dense)             (None, 2541)              10410477  
                                                                 
=================================================================
Total params: 10524077 (40.15 MB)
Trainable params: 10523565 (40.14 MB)
Non-trainable params: 512 (2.00 KB)
_________________________________________________________________
None
Models in tmp ['tmp/060.22309.model', 'tmp/061.22548.model', 'tmp/062.22848.model', 'tmp/063.23104.model', 'tmp/064.23382.model', 'tmp/065.23559.model', 'tmp/066.23574.model', 'tmp/067.23637.model', 'tmp/068.23646.model', 'tmp/069.23655.model', 'tmp/070.23696.model', 'tmp/071.23702.model', 'tmp/072.23708.model', 'tmp/073.23741.model', 'tmp/074.24987.model', 'tmp/075.26252.model', 'tmp/076.27515.model', 'tmp/077.28759.model', 'tmp/078.30021.model', 'tmp/079.31282.model']
Load model tmp/079.31282.model
Leftover images from failed episode: ['_out_16rl_custom2/080_020266.png', '_out_16rl_custom2/080_020267.png', '_out_16rl_custom2/080_020268.png', '_out_16rl_custom2/080_020269.png', '_out_16rl_custom2/080_020270.png', '_out_16rl_custom2/080_020271.png', '_out_16rl_custom2/080_020272.png', '_out_16rl_custom2/080_020274.png', '_out_16rl_custom2/080_020275.png', '_out_16rl_custom2/080_020276.png', '_out_16rl_custom2/080_020278.png', '_out_16rl_custom2/080_020279.png', '_out_16rl_custom2/080_020280.png', '_out_16rl_custom2/080_020281.png', '_out_16rl_custom2/080_020282.png', '_out_16rl_custom2/080_020283.png', '_out_16rl_custom2/080_020285.png', '_out_16rl_custom2/080_020287.png', '_out_16rl_custom2/080_020289.png', '_out_16rl_custom2/080_020290.png', '_out_16rl_custom2/080_020291.png', '_out_16rl_custom2/080_020292.png', '_out_16rl_custom2/080_020293.png', '_out_16rl_custom2/080_020295.png', '_out_16rl_custom2/080_020296.png', '_out_16rl_custom2/080_020298.png', '_out_16rl_custom2/080_020299.png', '_out_16rl_custom2/080_020301.png', '_out_16rl_custom2/080_020302.png', '_out_16rl_custom2/080_020303.png', '_out_16rl_custom2/080_020304.png', '_out_16rl_custom2/080_020305.png', '_out_16rl_custom2/080_020307.png', '_out_16rl_custom2/080_020308.png', '_out_16rl_custom2/080_020309.png', '_out_16rl_custom2/080_020311.png', '_out_16rl_custom2/080_020312.png', '_out_16rl_custom2/080_020313.png', '_out_16rl_custom2/080_020315.png', '_out_16rl_custom2/080_020316.png', '_out_16rl_custom2/080_020317.png', '_out_16rl_custom2/080_020319.png', '_out_16rl_custom2/080_020320.png', '_out_16rl_custom2/080_020321.png', '_out_16rl_custom2/080_020322.png', '_out_16rl_custom2/080_020323.png', '_out_16rl_custom2/080_020324.png', '_out_16rl_custom2/080_020325.png', '_out_16rl_custom2/080_020326.png', '_out_16rl_custom2/080_020327.png', '_out_16rl_custom2/080_020328.png', '_out_16rl_custom2/080_020329.png', '_out_16rl_custom2/080_020331.png']
WARNING: Version mismatch detected: You are trying to connect to a simulator that might be incompatible with this API 
WARNING: Client API version     = 0.9.15 
WARNING: Simulator API version  = 0.9.14 
2023-12-30 16:50:39.645425: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904
2023-12-30 16:50:40.602861: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f8fd355e120 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-12-30 16:50:40.602876: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 SUPER, Compute Capability 7.5
2023-12-30 16:50:40.605785: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1703973040.682264 2306450 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
  0%|          | 0/921 [00:00<?, ?episode/s]
Started episode 80 of 1000
Finished episode 80 of 1000
Saved model from episode 80. Count of epochs trained: 31530
  0%|          | 1/921 [02:37<40:20:37, 157.87s/episode]
Started episode 81 of 1000
Finished episode 81 of 1000
Saved model from episode 81. Count of epochs trained: 31830
  0%|          | 2/921 [05:14<40:07:25, 157.18s/episode]
Started episode 82 of 1000
Finished episode 82 of 1000
Saved model from episode 82. Count of epochs trained: 32126
  0%|          | 3/921 [07:50<39:55:50, 156.59s/episode]
Started episode 83 of 1000
Finished episode 83 of 1000
Saved model from episode 83. Count of epochs trained: 32417
  0%|          | 4/921 [10:25<39:44:35, 156.03s/episode]
Started episode 84 of 1000
Finished episode 84 of 1000
Saved model from episode 84. Count of epochs trained: 32704
  1%|          | 5/921 [12:59<39:32:38, 155.41s/episode]
Started episode 85 of 1000
Finished episode 85 of 1000
Count of epochs trained: 32987	Goal: 33943
Count of epochs trained: 33110	Goal: 33943
Count of epochs trained: 33234	Goal: 33943
Count of epochs trained: 33358	Goal: 33943
Count of epochs trained: 33483	Goal: 33943
Count of epochs trained: 33608	Goal: 33943
Count of epochs trained: 33733	Goal: 33943
Count of epochs trained: 33858	Goal: 33943
Saved model from episode 85. Count of epochs trained: 33984
  1%|          | 6/921 [23:34<80:55:39, 318.40s/episode]
Started episode 86 of 1000
Finished episode 86 of 1000
Count of epochs trained: 34277	Goal: 35223
Count of epochs trained: 34403	Goal: 35223
Count of epochs trained: 34528	Goal: 35223
Count of epochs trained: 34653	Goal: 35223
Count of epochs trained: 34778	Goal: 35223
Count of epochs trained: 34902	Goal: 35223
Count of epochs trained: 35028	Goal: 35223
Count of epochs trained: 35153	Goal: 35223
Saved model from episode 86. Count of epochs trained: 35279
  1%|          | 7/921 [34:10<107:10:02, 422.10s/episode]
Started episode 87 of 1000
Finished episode 87 of 1000
Count of epochs trained: 35302	Goal: 36518
Count of epochs trained: 35427	Goal: 36518
Count of epochs trained: 35553	Goal: 36518
Count of epochs trained: 35678	Goal: 36518
Count of epochs trained: 35803	Goal: 36518
Count of epochs trained: 35929	Goal: 36518
Count of epochs trained: 36054	Goal: 36518
Count of epochs trained: 36179	Goal: 36518
Count of epochs trained: 36304	Goal: 36518
Count of epochs trained: 36429	Goal: 36518
Saved model from episode 87. Count of epochs trained: 36555
  1%|          | 8/921 [44:23<122:29:42, 483.00s/episode]
Started episode 88 of 1000
Finished episode 88 of 1000
Count of epochs trained: 36655	Goal: 37794
Count of epochs trained: 36779	Goal: 37794
Count of epochs trained: 36904	Goal: 37794
Count of epochs trained: 37028	Goal: 37794
Count of epochs trained: 37152	Goal: 37794
Count of epochs trained: 37276	Goal: 37794
Count of epochs trained: 37401	Goal: 37794
Count of epochs trained: 37525	Goal: 37794
Count of epochs trained: 37649	Goal: 37794
Count of epochs trained: 37773	Goal: 37794
Saved model from episode 88. Count of epochs trained: 37898
  1%|          | 9/921 [55:17<135:55:13, 536.53s/episode]
Started episode 89 of 1000
Finished episode 89 of 1000
Count of epochs trained: 37991	Goal: 39137
Count of epochs trained: 38116	Goal: 39137
Count of epochs trained: 38240	Goal: 39137
Count of epochs trained: 38365	Goal: 39137
Count of epochs trained: 38490	Goal: 39137
Count of epochs trained: 38615	Goal: 39137
Count of epochs trained: 38739	Goal: 39137
Count of epochs trained: 38864	Goal: 39137
Count of epochs trained: 38988	Goal: 39137
Count of epochs trained: 39113	Goal: 39137
Saved model from episode 89. Count of epochs trained: 39238
  1%|1         | 10/921 [1:06:09<144:43:25, 571.90s/episode]
Started episode 90 of 1000
Finished episode 90 of 1000
Count of epochs trained: 39336	Goal: 40477
Count of epochs trained: 39461	Goal: 40477
Count of epochs trained: 39585	Goal: 40477
Count of epochs trained: 39710	Goal: 40477
Count of epochs trained: 39834	Goal: 40477
Count of epochs trained: 39959	Goal: 40477
Count of epochs trained: 40083	Goal: 40477
Count of epochs trained: 40208	Goal: 40477
Count of epochs trained: 40332	Goal: 40477
Count of epochs trained: 40447	Goal: 40477
Saved model from episode 90. Count of epochs trained: 40565
  1%|1         | 11/921 [1:17:03<150:58:54, 597.29s/episode]
Started episode 91 of 1000
Finished episode 91 of 1000
Count of epochs trained: 40620	Goal: 41804
Count of epochs trained: 40744	Goal: 41804
Count of epochs trained: 40868	Goal: 41804
Count of epochs trained: 40993	Goal: 41804
Count of epochs trained: 41117	Goal: 41804
Count of epochs trained: 41241	Goal: 41804
Count of epochs trained: 41365	Goal: 41804
Count of epochs trained: 41490	Goal: 41804
Count of epochs trained: 41614	Goal: 41804
Count of epochs trained: 41738	Goal: 41804
Saved model from episode 91. Count of epochs trained: 41862
  1%|1         | 12/921 [1:27:35<153:26:03, 607.66s/episode]
Started episode 92 of 1000
Finished episode 92 of 1000
Count of epochs trained: 41898	Goal: 43101
Count of epochs trained: 42021	Goal: 43101
Count of epochs trained: 42146	Goal: 43101
Count of epochs trained: 42269	Goal: 43101
Count of epochs trained: 42393	Goal: 43101
Count of epochs trained: 42517	Goal: 43101
Count of epochs trained: 42641	Goal: 43101
Count of epochs trained: 42766	Goal: 43101
Count of epochs trained: 42890	Goal: 43101
Count of epochs trained: 43015	Goal: 43101
Saved model from episode 92. Count of epochs trained: 43140
  1%|1         | 13/921 [1:37:56<154:16:03, 611.63s/episode]
Started episode 93 of 1000
Finished episode 93 of 1000
Count of epochs trained: 43261	Goal: 44379
Count of epochs trained: 43385	Goal: 44379
Count of epochs trained: 43510	Goal: 44379
Count of epochs trained: 43634	Goal: 44379
Count of epochs trained: 43759	Goal: 44379
Count of epochs trained: 43883	Goal: 44379
Count of epochs trained: 44008	Goal: 44379
Count of epochs trained: 44132	Goal: 44379
Count of epochs trained: 44256	Goal: 44379
Saved model from episode 93. Count of epochs trained: 44381
  2%|1         | 14/921 [1:48:03<153:46:18, 610.34s/episode]
Started episode 94 of 1000
Finished episode 94 of 1000
Count of epochs trained: 44388	Goal: 45620
Count of epochs trained: 44512	Goal: 45620
Count of epochs trained: 44637	Goal: 45620
Count of epochs trained: 44761	Goal: 45620
Count of epochs trained: 44885	Goal: 45620
Count of epochs trained: 45010	Goal: 45620
Count of epochs trained: 45134	Goal: 45620
Count of epochs trained: 45258	Goal: 45620
Count of epochs trained: 45382	Goal: 45620
Count of epochs trained: 45507	Goal: 45620
Saved model from episode 94. Count of epochs trained: 45632
  2%|1         | 15/921 [1:58:08<153:12:51, 608.80s/episode]
Started episode 95 of 1000
Finished episode 95 of 1000
Count of epochs trained: 45689	Goal: 46871
Count of epochs trained: 45813	Goal: 46871
Count of epochs trained: 45937	Goal: 46871
Count of epochs trained: 46062	Goal: 46871
Count of epochs trained: 46187	Goal: 46871
Count of epochs trained: 46311	Goal: 46871
Count of epochs trained: 46436	Goal: 46871
Count of epochs trained: 46560	Goal: 46871
Count of epochs trained: 46684	Goal: 46871
Count of epochs trained: 46809	Goal: 46871
Saved model from episode 95. Count of epochs trained: 46935
  2%|1         | 16/921 [2:08:41<154:52:43, 616.09s/episode]
Started episode 96 of 1000
Finished episode 96 of 1000
Count of epochs trained: 47223	Goal: 48174
Count of epochs trained: 47348	Goal: 48174
Count of epochs trained: 47473	Goal: 48174
Count of epochs trained: 47597	Goal: 48174
Count of epochs trained: 47721	Goal: 48174
Count of epochs trained: 47845	Goal: 48174
Count of epochs trained: 47970	Goal: 48174
Count of epochs trained: 48093	Goal: 48174
Saved model from episode 96. Count of epochs trained: 48218
  2%|1         | 17/921 [2:19:23<156:39:24, 623.85s/episode]
Started episode 97 of 1000
Finished episode 97 of 1000
Count of epochs trained: 48489	Goal: 49457
Count of epochs trained: 48613	Goal: 49457
Count of epochs trained: 48737	Goal: 49457
Count of epochs trained: 48861	Goal: 49457
Count of epochs trained: 48985	Goal: 49457
Count of epochs trained: 49110	Goal: 49457
Count of epochs trained: 49234	Goal: 49457
Count of epochs trained: 49358	Goal: 49457
Saved model from episode 97. Count of epochs trained: 49484
  2%|1         | 18/921 [2:29:57<157:14:19, 626.87s/episode]
Started episode 98 of 1000
Finished episode 98 of 1000
Count of epochs trained: 49507	Goal: 50723
Count of epochs trained: 49631	Goal: 50723
Count of epochs trained: 49756	Goal: 50723
Count of epochs trained: 49880	Goal: 50723
Count of epochs trained: 50005	Goal: 50723
Count of epochs trained: 50129	Goal: 50723
Count of epochs trained: 50253	Goal: 50723
Count of epochs trained: 50377	Goal: 50723
Count of epochs trained: 50501	Goal: 50723
Count of epochs trained: 50625	Goal: 50723
Saved model from episode 98. Count of epochs trained: 50749
  2%|2         | 19/921 [2:40:11<156:07:32, 623.12s/episode]
Started episode 99 of 1000
Finished episode 99 of 1000
Count of epochs trained: 50767	Goal: 51988
Count of epochs trained: 50890	Goal: 51988
Count of epochs trained: 51014	Goal: 51988
Count of epochs trained: 51138	Goal: 51988
Count of epochs trained: 51261	Goal: 51988
Count of epochs trained: 51385	Goal: 51988
Count of epochs trained: 51508	Goal: 51988
Count of epochs trained: 51632	Goal: 51988
Count of epochs trained: 51755	Goal: 51988
Count of epochs trained: 51878	Goal: 51988
Saved model from episode 99. Count of epochs trained: 52002
  2%|2         | 20/921 [2:50:22<155:02:41, 619.49s/episode]
Started episode 100 of 1000
Finished episode 100 of 1000
Count of epochs trained: 52253	Goal: 53241
Count of epochs trained: 52376	Goal: 53241
Count of epochs trained: 52502	Goal: 53241
Count of epochs trained: 52626	Goal: 53241
Count of epochs trained: 52750	Goal: 53241
Count of epochs trained: 52873	Goal: 53241
Count of epochs trained: 52997	Goal: 53241
Count of epochs trained: 53121	Goal: 53241
Saved model from episode 100. Count of epochs trained: 53245
  2%|2         | 21/921 [3:00:49<155:24:37, 621.64s/episode]
Started episode 101 of 1000
Finished episode 101 of 1000
Count of epochs trained: 53254	Goal: 54484
Count of epochs trained: 53366	Goal: 54484
Count of epochs trained: 53481	Goal: 54484
Count of epochs trained: 53605	Goal: 54484
Count of epochs trained: 53726	Goal: 54484
Count of epochs trained: 53848	Goal: 54484
Count of epochs trained: 53973	Goal: 54484
Count of epochs trained: 54096	Goal: 54484
Count of epochs trained: 54221	Goal: 54484
Count of epochs trained: 54345	Goal: 54484
Count of epochs trained: 54469	Goal: 54484
Saved model from episode 101. Count of epochs trained: 54593
  2%|2         | 22/921 [3:11:57<158:40:27, 635.40s/episode]
Started episode 102 of 1000
Finished episode 102 of 1000
Count of epochs trained: 54855	Goal: 55832
Count of epochs trained: 54978	Goal: 55832
Count of epochs trained: 55102	Goal: 55832
Count of epochs trained: 55226	Goal: 55832
Count of epochs trained: 55349	Goal: 55832
Count of epochs trained: 55472	Goal: 55832
Count of epochs trained: 55595	Goal: 55832
Count of epochs trained: 55718	Goal: 55832
Saved model from episode 102. Count of epochs trained: 55843
  2%|2         | 23/921 [3:22:32<158:29:37, 635.39s/episode]
Started episode 103 of 1000
Finished episode 103 of 1000
Count of epochs trained: 55851	Goal: 57082
Count of epochs trained: 55975	Goal: 57082
Count of epochs trained: 56100	Goal: 57082
Count of epochs trained: 56225	Goal: 57082
Count of epochs trained: 56350	Goal: 57082
Count of epochs trained: 56475	Goal: 57082
Count of epochs trained: 56600	Goal: 57082
Count of epochs trained: 56724	Goal: 57082
Count of epochs trained: 56849	Goal: 57082
Count of epochs trained: 56974	Goal: 57082
Saved model from episode 103. Count of epochs trained: 57099
  3%|2         | 24/921 [3:32:38<156:06:10, 626.50s/episode]
Started episode 104 of 1000
Finished episode 104 of 1000
Count of epochs trained: 57251	Goal: 58338
Count of epochs trained: 57375	Goal: 58338
Count of epochs trained: 57500	Goal: 58338
Count of epochs trained: 57625	Goal: 58338
Count of epochs trained: 57750	Goal: 58338
Count of epochs trained: 57875	Goal: 58338
Count of epochs trained: 57999	Goal: 58338
Count of epochs trained: 58124	Goal: 58338
Count of epochs trained: 58250	Goal: 58338
Saved model from episode 104. Count of epochs trained: 58375
  3%|2         | 25/921 [3:43:07<156:07:22, 627.28s/episode]
Started episode 105 of 1000
Finished episode 105 of 1000
Count of epochs trained: 58390	Goal: 59614
Count of epochs trained: 58515	Goal: 59614
Count of epochs trained: 58639	Goal: 59614
Count of epochs trained: 58764	Goal: 59614
Count of epochs trained: 58889	Goal: 59614
Count of epochs trained: 59014	Goal: 59614
Count of epochs trained: 59138	Goal: 59614
Count of epochs trained: 59263	Goal: 59614
Count of epochs trained: 59388	Goal: 59614
Count of epochs trained: 59512	Goal: 59614
Saved model from episode 105. Count of epochs trained: 59638
  3%|2         | 26/921 [3:53:17<154:40:09, 622.13s/episode]
Started episode 106 of 1000
Finished episode 106 of 1000
Count of epochs trained: 59647	Goal: 60877
Count of epochs trained: 59772	Goal: 60877
Count of epochs trained: 59897	Goal: 60877
Count of epochs trained: 60022	Goal: 60877
Count of epochs trained: 60147	Goal: 60877
Count of epochs trained: 60272	Goal: 60877
Count of epochs trained: 60397	Goal: 60877
Count of epochs trained: 60522	Goal: 60877
Count of epochs trained: 60647	Goal: 60877
Count of epochs trained: 60771	Goal: 60877
Saved model from episode 106. Count of epochs trained: 60897
  3%|2         | 27/921 [4:03:24<153:20:43, 617.50s/episode]
Started episode 107 of 1000
Finished episode 107 of 1000
Count of epochs trained: 61160	Goal: 62136
Count of epochs trained: 61285	Goal: 62136
Count of epochs trained: 61409	Goal: 62136
Count of epochs trained: 61534	Goal: 62136
Count of epochs trained: 61658	Goal: 62136
Count of epochs trained: 61783	Goal: 62136
Count of epochs trained: 61906	Goal: 62136
Count of epochs trained: 62031	Goal: 62136
Saved model from episode 107. Count of epochs trained: 62155
  3%|3         | 28/921 [4:14:00<154:32:52, 623.04s/episode]
Started episode 108 of 1000
Finished episode 108 of 1000
Count of epochs trained: 62164	Goal: 63394
Count of epochs trained: 62288	Goal: 63394
Count of epochs trained: 62412	Goal: 63394
Count of epochs trained: 62536	Goal: 63394
Count of epochs trained: 62660	Goal: 63394
Count of epochs trained: 62784	Goal: 63394
Count of epochs trained: 62908	Goal: 63394
Count of epochs trained: 63032	Goal: 63394
Count of epochs trained: 63156	Goal: 63394
Count of epochs trained: 63281	Goal: 63394
Saved model from episode 108. Count of epochs trained: 63406
  3%|3         | 29/921 [4:24:06<153:08:45, 618.08s/episode]
Started episode 109 of 1000
Finished episode 109 of 1000
Count of epochs trained: 63427	Goal: 64645
Count of epochs trained: 63552	Goal: 64645
Count of epochs trained: 63676	Goal: 64645
Count of epochs trained: 63800	Goal: 64645
Count of epochs trained: 63923	Goal: 64645
Count of epochs trained: 64041	Goal: 64645
Count of epochs trained: 64165	Goal: 64645
