Start run at count 1
4.26.2-0+++UE4+Release-4.26 522 0
Disabling core dumps.
2023-12-29 21:15:11.056231: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-12-29 21:15:11.207536: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2023-12-29 21:15:11.207593: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2023-12-29 21:15:11.226765: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2023-12-29 21:15:11.233877: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-12-29 21:15:11.871055: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-12-29 21:15:12.404371: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-12-29 21:15:12.463000: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-12-29 21:15:12.463294: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-12-29 21:15:12.466488: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-12-29 21:15:12.466687: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-12-29 21:15:12.466827: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-12-29 21:15:13.450325: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-12-29 21:15:13.450507: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-12-29 21:15:13.450621: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-12-29 21:15:13.450759: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4449 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 SUPER, pci bus id: 0000:02:00.0, compute capability: 7.5
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d_input (InputLayer)   [(None, 128, 128, 3)]     0         
                                                                 
 conv2d (Conv2D)             (None, 128, 128, 64)      1792      
                                                                 
 max_pooling2d (MaxPooling2  (None, 64, 64, 64)        0         
 D)                                                              
                                                                 
 batch_normalization (Batch  (None, 64, 64, 64)        256       
 Normalization)                                                  
                                                                 
 activation (Activation)     (None, 64, 64, 64)        0         
                                                                 
 conv2d_1 (Conv2D)           (None, 64, 64, 64)        36928     
                                                                 
 max_pooling2d_1 (MaxPoolin  (None, 32, 32, 64)        0         
 g2D)                                                            
                                                                 
 batch_normalization_1 (Bat  (None, 32, 32, 64)        256       
 chNormalization)                                                
                                                                 
 activation_1 (Activation)   (None, 32, 32, 64)        0         
                                                                 
 conv2d_2 (Conv2D)           (None, 32, 32, 64)        36928     
                                                                 
 max_pooling2d_2 (MaxPoolin  (None, 16, 16, 64)        0         
 g2D)                                                            
                                                                 
 batch_normalization_2 (Bat  (None, 16, 16, 64)        256       
 chNormalization)                                                
                                                                 
 activation_2 (Activation)   (None, 16, 16, 64)        0         
                                                                 
 conv2d_3 (Conv2D)           (None, 16, 16, 64)        36928     
                                                                 
 max_pooling2d_3 (MaxPoolin  (None, 8, 8, 64)          0         
 g2D)                                                            
                                                                 
 batch_normalization_3 (Bat  (None, 8, 8, 64)          256       
 chNormalization)                                                
                                                                 
 activation_3 (Activation)   (None, 8, 8, 64)          0         
                                                                 
 flatten (Flatten)           (None, 4096)              0         
                                                                 
 dense (Dense)               (None, 2541)              10410477  
                                                                 
=================================================================
Total params: 10524077 (40.15 MB)
Trainable params: 10523565 (40.14 MB)
Non-trainable params: 512 (2.00 KB)
_________________________________________________________________
None
Model: "model_1"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d_4_input (InputLayer  [(None, 128, 128, 3)]     0         
 )                                                               
                                                                 
 conv2d_4 (Conv2D)           (None, 128, 128, 64)      1792      
                                                                 
 max_pooling2d_4 (MaxPoolin  (None, 64, 64, 64)        0         
 g2D)                                                            
                                                                 
 batch_normalization_4 (Bat  (None, 64, 64, 64)        256       
 chNormalization)                                                
                                                                 
 activation_4 (Activation)   (None, 64, 64, 64)        0         
                                                                 
 conv2d_5 (Conv2D)           (None, 64, 64, 64)        36928     
                                                                 
 max_pooling2d_5 (MaxPoolin  (None, 32, 32, 64)        0         
 g2D)                                                            
                                                                 
 batch_normalization_5 (Bat  (None, 32, 32, 64)        256       
 chNormalization)                                                
                                                                 
 activation_5 (Activation)   (None, 32, 32, 64)        0         
                                                                 
 conv2d_6 (Conv2D)           (None, 32, 32, 64)        36928     
                                                                 
 max_pooling2d_6 (MaxPoolin  (None, 16, 16, 64)        0         
 g2D)                                                            
                                                                 
 batch_normalization_6 (Bat  (None, 16, 16, 64)        256       
 chNormalization)                                                
                                                                 
 activation_6 (Activation)   (None, 16, 16, 64)        0         
                                                                 
 conv2d_7 (Conv2D)           (None, 16, 16, 64)        36928     
                                                                 
 max_pooling2d_7 (MaxPoolin  (None, 8, 8, 64)          0         
 g2D)                                                            
                                                                 
 batch_normalization_7 (Bat  (None, 8, 8, 64)          256       
 chNormalization)                                                
                                                                 
 activation_7 (Activation)   (None, 8, 8, 64)          0         
                                                                 
 flatten_1 (Flatten)         (None, 4096)              0         
                                                                 
 dense_1 (Dense)             (None, 2541)              10410477  
                                                                 
=================================================================
Total params: 10524077 (40.15 MB)
Trainable params: 10523565 (40.14 MB)
Non-trainable params: 512 (2.00 KB)
_________________________________________________________________
None
Model: "model_2"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d_8_input (InputLayer  [(None, 128, 128, 3)]     0         
 )                                                               
                                                                 
 conv2d_8 (Conv2D)           (None, 128, 128, 64)      1792      
                                                                 
 max_pooling2d_8 (MaxPoolin  (None, 64, 64, 64)        0         
 g2D)                                                            
                                                                 
 batch_normalization_8 (Bat  (None, 64, 64, 64)        256       
 chNormalization)                                                
                                                                 
 activation_8 (Activation)   (None, 64, 64, 64)        0         
                                                                 
 conv2d_9 (Conv2D)           (None, 64, 64, 64)        36928     
                                                                 
 max_pooling2d_9 (MaxPoolin  (None, 32, 32, 64)        0         
 g2D)                                                            
                                                                 
 batch_normalization_9 (Bat  (None, 32, 32, 64)        256       
 chNormalization)                                                
                                                                 
 activation_9 (Activation)   (None, 32, 32, 64)        0         
                                                                 
 conv2d_10 (Conv2D)          (None, 32, 32, 64)        36928     
                                                                 
 max_pooling2d_10 (MaxPooli  (None, 16, 16, 64)        0         
 ng2D)                                                           
                                                                 
 batch_normalization_10 (Ba  (None, 16, 16, 64)        256       
 tchNormalization)                                               
                                                                 
 activation_10 (Activation)  (None, 16, 16, 64)        0         
                                                                 
 conv2d_11 (Conv2D)          (None, 16, 16, 64)        36928     
                                                                 
 max_pooling2d_11 (MaxPooli  (None, 8, 8, 64)          0         
 ng2D)                                                           
                                                                 
 batch_normalization_11 (Ba  (None, 8, 8, 64)          256       
 tchNormalization)                                               
                                                                 
 activation_11 (Activation)  (None, 8, 8, 64)          0         
                                                                 
 flatten_2 (Flatten)         (None, 4096)              0         
                                                                 
 dense_2 (Dense)             (None, 2541)              10410477  
                                                                 
=================================================================
Total params: 10524077 (40.15 MB)
Trainable params: 10523565 (40.14 MB)
Non-trainable params: 512 (2.00 KB)
_________________________________________________________________
None
WARNING: Version mismatch detected: You are trying to connect to a simulator that might be incompatible with this API 
WARNING: Client API version     = 0.9.15 
WARNING: Simulator API version  = 0.9.14 
2023-12-29 21:15:22.596939: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904
2023-12-29 21:15:23.674758: I external/local_xla/xla/service/service.cc:168] XLA service 0x7fd0ef936a40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-12-29 21:15:23.674773: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 SUPER, Compute Capability 7.5
2023-12-29 21:15:23.679986: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1703902523.759166 3391871 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
  0%|          | 0/1000 [00:00<?, ?episode/s]
Started episode 1 of 1000
Finished episode 1 of 1000
Saved model from episode 1. Count of epochs trained: 0
  0%|          | 1/1000 [00:37<10:19:29, 37.21s/episode]
Started episode 2 of 1000
Finished training first epoch.
Finished episode 2 of 1000
Saved model from episode 2. Count of epochs trained: 4
  0%|          | 2/1000 [01:02<8:26:30, 30.45s/episode] 
Started episode 3 of 1000
Finished episode 3 of 1000
Saved model from episode 3. Count of epochs trained: 22
  0%|          | 3/1000 [01:17<6:27:07, 23.30s/episode]
Started episode 4 of 1000
Finished episode 4 of 1000
Saved model from episode 4. Count of epochs trained: 43
  0%|          | 4/1000 [01:34<5:41:18, 20.56s/episode]
Started episode 5 of 1000
Finished episode 5 of 1000
Saved model from episode 5. Count of epochs trained: 90
  0%|          | 5/1000 [02:11<7:22:03, 26.66s/episode]
Started episode 6 of 1000
Finished episode 6 of 1000
Saved model from episode 6. Count of epochs trained: 106
  1%|          | 6/1000 [02:24<6:05:19, 22.05s/episode]
Started episode 7 of 1000
Finished episode 7 of 1000
Saved model from episode 7. Count of epochs trained: 122
  1%|          | 7/1000 [02:37<5:14:23, 19.00s/episode]
Started episode 8 of 1000
Finished episode 8 of 1000
Saved model from episode 8. Count of epochs trained: 132
  1%|          | 8/1000 [02:45<4:18:42, 15.65s/episode]
Started episode 9 of 1000
Finished episode 9 of 1000
Saved model from episode 9. Count of epochs trained: 143
  1%|          | 9/1000 [02:54<3:44:32, 13.60s/episode]
Started episode 10 of 1000
Finished episode 10 of 1000
Saved model from episode 10. Count of epochs trained: 152
  1%|1         | 10/1000 [03:02<3:15:43, 11.86s/episode]
Started episode 11 of 1000
Finished episode 11 of 1000
Saved model from episode 11. Count of epochs trained: 164
  1%|1         | 11/1000 [03:12<3:06:10, 11.29s/episode]
Started episode 12 of 1000
Finished episode 12 of 1000
Saved model from episode 12. Count of epochs trained: 175
  1%|1         | 12/1000 [03:22<2:57:54, 10.80s/episode]
Started episode 13 of 1000
Finished episode 13 of 1000
Saved model from episode 13. Count of epochs trained: 184
  1%|1         | 13/1000 [03:30<2:42:34,  9.88s/episode]
Started episode 14 of 1000
Finished episode 14 of 1000
Saved model from episode 14. Count of epochs trained: 194
  1%|1         | 14/1000 [03:39<2:37:22,  9.58s/episode]
Started episode 15 of 1000
Finished episode 15 of 1000
Saved model from episode 15. Count of epochs trained: 202
  2%|1         | 15/1000 [03:46<2:26:25,  8.92s/episode]
Started episode 16 of 1000
Finished episode 16 of 1000
Saved model from episode 16. Count of epochs trained: 212
  2%|1         | 16/1000 [03:55<2:25:59,  8.90s/episode]
Started episode 17 of 1000
Finished episode 17 of 1000
Saved model from episode 17. Count of epochs trained: 219
  2%|1         | 17/1000 [04:01<2:13:18,  8.14s/episode]
Started episode 18 of 1000
Finished episode 18 of 1000
Saved model from episode 18. Count of epochs trained: 226
  2%|1         | 18/1000 [04:08<2:04:46,  7.62s/episode]
Started episode 19 of 1000
Finished episode 19 of 1000
Saved model from episode 19. Count of epochs trained: 235
  2%|1         | 19/1000 [04:16<2:07:17,  7.79s/episode]
Started episode 20 of 1000
Finished episode 20 of 1000
Saved model from episode 20. Count of epochs trained: 246
  2%|2         | 20/1000 [04:26<2:19:43,  8.55s/episode]
Started episode 21 of 1000
Finished episode 21 of 1000
Saved model from episode 21. Count of epochs trained: 260
  2%|2         | 21/1000 [04:38<2:37:20,  9.64s/episode]
Started episode 22 of 1000
Finished episode 22 of 1000
Saved model from episode 22. Count of epochs trained: 266
  2%|2         | 22/1000 [04:44<2:16:30,  8.37s/episode]
Started episode 23 of 1000
Finished episode 23 of 1000
Saved model from episode 23. Count of epochs trained: 271
  2%|2         | 23/1000 [04:49<2:00:24,  7.39s/episode]
Started episode 24 of 1000
Finished episode 24 of 1000
Saved model from episode 24. Count of epochs trained: 276
  2%|2         | 24/1000 [04:54<1:48:34,  6.68s/episode]
Started episode 25 of 1000
Finished episode 25 of 1000
Saved model from episode 25. Count of epochs trained: 282
  2%|2         | 25/1000 [05:00<1:43:49,  6.39s/episode]
Started episode 26 of 1000
Finished episode 26 of 1000
Saved model from episode 26. Count of epochs trained: 323
  3%|2         | 26/1000 [05:36<4:09:22, 15.36s/episode]
Started episode 27 of 1000
Finished episode 27 of 1000
Saved model from episode 27. Count of epochs trained: 361
  3%|2         | 27/1000 [06:10<5:40:32, 21.00s/episode]
Started episode 28 of 1000
Finished episode 28 of 1000
Saved model from episode 28. Count of epochs trained: 375
  3%|2         | 28/1000 [06:23<5:01:07, 18.59s/episode]
Started episode 29 of 1000
Finished episode 29 of 1000
Saved model from episode 29. Count of epochs trained: 379
  3%|2         | 29/1000 [06:27<3:48:19, 14.11s/episode]
Started episode 30 of 1000
Finished episode 30 of 1000
Saved model from episode 30. Count of epochs trained: 382
  3%|3         | 30/1000 [06:30<2:57:43, 10.99s/episode]
Started episode 31 of 1000
Finished episode 31 of 1000
Saved model from episode 31. Count of epochs trained: 386
  3%|3         | 31/1000 [06:34<2:22:02,  8.80s/episode]
Started episode 32 of 1000
Finished episode 32 of 1000
Saved model from episode 32. Count of epochs trained: 389
  3%|3         | 32/1000 [06:38<1:55:43,  7.17s/episode]
Started episode 33 of 1000
Finished episode 33 of 1000
Saved model from episode 33. Count of epochs trained: 396
  3%|3         | 33/1000 [06:44<1:51:41,  6.93s/episode]
Started episode 34 of 1000
Finished episode 34 of 1000
Saved model from episode 34. Count of epochs trained: 408
  3%|3         | 34/1000 [06:55<2:11:20,  8.16s/episode]
Started episode 35 of 1000
Finished episode 35 of 1000
Saved model from episode 35. Count of epochs trained: 419
  4%|3         | 35/1000 [07:05<2:22:28,  8.86s/episode]
Started episode 36 of 1000
Finished episode 36 of 1000
Saved model from episode 36. Count of epochs trained: 443
  4%|3         | 36/1000 [07:28<3:27:22, 12.91s/episode]
Started episode 37 of 1000
Finished episode 37 of 1000
Saved model from episode 37. Count of epochs trained: 533
  4%|3         | 37/1000 [08:52<9:08:50, 34.20s/episode]
Started episode 38 of 1000
Finished episode 38 of 1000
Saved model from episode 38. Count of epochs trained: 577
  4%|3         | 38/1000 [09:37<10:03:50, 37.66s/episode]
Started episode 39 of 1000
Finished episode 39 of 1000
Saved model from episode 39. Count of epochs trained: 588
  4%|3         | 39/1000 [09:48<7:52:23, 29.49s/episode] 
Started episode 40 of 1000
Finished episode 40 of 1000
Saved model from episode 40. Count of epochs trained: 651
  4%|4         | 40/1000 [10:48<10:18:03, 38.63s/episode]
Started episode 41 of 1000
Finished episode 41 of 1000
Saved model from episode 41. Count of epochs trained: 657
  4%|4         | 41/1000 [10:54<7:42:25, 28.93s/episode] 
Started episode 42 of 1000
Finished episode 42 of 1000
Saved model from episode 42. Count of epochs trained: 662
  4%|4         | 42/1000 [11:00<5:52:32, 22.08s/episode]
Started episode 43 of 1000
Finished episode 43 of 1000
Saved model from episode 43. Count of epochs trained: 668
  4%|4         | 43/1000 [11:07<4:38:16, 17.45s/episode]
Started episode 44 of 1000
Finished episode 44 of 1000
Saved model from episode 44. Count of epochs trained: 675
  4%|4         | 44/1000 [11:15<3:51:49, 14.55s/episode]
Started episode 45 of 1000
Finished episode 45 of 1000
Saved model from episode 45. Count of epochs trained: 681
  4%|4         | 45/1000 [11:22<3:19:34, 12.54s/episode]
Started episode 46 of 1000
